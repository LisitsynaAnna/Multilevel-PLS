{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import argparse\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import copy\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(X, Y, subj, num_samples, mean, deviation, ddof, method, feature_selection, model_params,\n",
    "               num_features, step, verbose_train, scaling):\n",
    "    # process the labels\n",
    "    if scaling:\n",
    "        y_temp = np.array(Y)\n",
    "        y_temp = descale_data(matrix=y_temp, deviation=deviation, ddof=ddof)  # descale\n",
    "        y_temp = y_temp + mean  # add mean\n",
    "        for j in range(len(y_temp)):\n",
    "            if y_temp[j] > 1:\n",
    "                y_temp[j] = 1\n",
    "            elif y_temp[j] < 0:\n",
    "                y_temp[j] = 0\n",
    "    else:\n",
    "        y_temp = Y + mean\n",
    "    y_temp = round_num(y_temp)\n",
    "    # print \"Y_temp: \", Y_temp\n",
    "\n",
    "    # choose, which classifier to use\n",
    "    if method == 'rf':  # build a generic Random Forest\n",
    "        model = RandomForestRegressor(n_estimators=model_params['n_trees'], random_state=0,\n",
    "                                      max_features=model_params['max_features'], max_depth=model_params['max_depth'],\n",
    "                                      min_samples_leaf=model_params['min_samples_leaf'])\n",
    "    elif method == 'pls':\n",
    "        model = PLSRegression(n_components=model_params['n_comp'], scale=False)  # initialize a generic PLS model\n",
    "\n",
    "    elif method == 'svm':\n",
    "        model = SVR(C=model_params['C'], epsilon=model_params['epsilon'], kernel=model_params['kernel'],\n",
    "                    gamma=model_params['gamma'], degree=model_params['degree'])\n",
    "    elif method == 'lda':\n",
    "        model = LinearDiscriminantAnalysis()\n",
    "    if method == 'nn':\n",
    "        from keras.wrappers.scikit_learn import KerasRegressor\n",
    "        from keras.models import Sequential\n",
    "        from keras.layers import Dense, Activation\n",
    "        import tensorflow\n",
    "        coeff = np.zeros(X.shape[1])\n",
    "        features = [True for f in range(X.shape[1])]\n",
    "        estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "        model = estimator\n",
    "        sfold = StratifiedKFold(n_splits=15)\n",
    "        results = cross_val_score(estimator, X, y_temp, cv=sfold)\n",
    "        estimator.fit(X, y_temp)\n",
    "        print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "        auc = 0\n",
    "        train_error = 0\n",
    "    else:\n",
    "        # choose a method for feature selection\n",
    "        if feature_selection == 'FromModel':\n",
    "            model_temp = copy.copy(model)\n",
    "            if method == 'svm' and model_params['kernel'] != 'linear':\n",
    "                model_temp = SVR(C=1, epsilon=1, kernel='linear')\n",
    "            model_temp.fit(X, Y)\n",
    "            model_temp = SelectFromModel(model, prefit=True)\n",
    "            features = model_temp.get_support()\n",
    "        elif feature_selection == 'rfecv':\n",
    "            rfe = RFECV(estimator=model, cv=20, step=step)\n",
    "            if method == 'svm' and model_params['kernel'] != 'linear':\n",
    "                rfe = SVR(C=1, epsilon=1, kernel='linear')\n",
    "            fit = rfe.fit(X, Y)\n",
    "            features = fit.support_\n",
    "        elif feature_selection == 'rfe':\n",
    "            model_temp = copy.copy(model)\n",
    "            if method == 'svm' and model_params['kernel'] != 'linear':\n",
    "                model_temp = SVR(C=1, epsilon=1, kernel='linear')\n",
    "            model_temp.fit(X, Y)\n",
    "            rfe = RFE(estimator=model, n_features_to_select=num_features, step=step)\n",
    "            fit = rfe.fit(X, Y)\n",
    "            features = fit.support_\n",
    "        elif feature_selection == 'pca':\n",
    "            pca = PCA(n_components=model_params['n_comp'])\n",
    "            fit = pca.fit(X)\n",
    "            features = (-np.mean(fit.components_, axis=0)).argsort()[:num_features]\n",
    "        elif feature_selection == 'lda':\n",
    "            clf = LinearDiscriminantAnalysis()\n",
    "            clf.fit(X, y_temp)\n",
    "            features = clf.coef_.argsort()[:num_features]\n",
    "        else:  # feature_selection is None:\n",
    "            features = [True for f in range(X.shape[1])]\n",
    "\n",
    "        # transform input to suit new dimensions\n",
    "        X_new = X[:, features]\n",
    "        if len(X_new.shape) == 3:\n",
    "            X_new = X_new.reshape(X_new.shape[0], X_new.shape[2])\n",
    "\n",
    "        # fit the model\n",
    "        if method == 'lda':\n",
    "            model.fit(X_new, y_temp)\n",
    "        elif method:\n",
    "            model.fit(X_new, Y)  # ACTUALLY getting the classifier model, fit model to data\n",
    "            pred = model.predict(X_new)  # predict the values on the train set\n",
    "\n",
    "        # get coefficients\n",
    "        if method == 'rf':\n",
    "            coeff = model.feature_importances_.flatten()\n",
    "        elif method == 'pls':\n",
    "            coeff = model.coef_\n",
    "            # print \"What about \", model.x_scores_\n",
    "            # print \"Mean of coeff: \", np.mean(model.coef_)\n",
    "            # print \"Standard deviation of coeff: \", np.std(model.coef_)\n",
    "            # print \"Max of coeff: \", np.amax(model.coef_)\n",
    "            # print \"Min of coeff: \", np.amin(model.coef_)\n",
    "            # print \"Mean of new coeff: \", np.mean(coeff)\n",
    "            # print \"Standard deviation of coeff: \", np.std(coeff)\n",
    "            # print \"Max of new coeff: \", np.amax(coeff)\n",
    "            # print \"Min of new coeff: \", np.amin(coeff)\n",
    "        elif method == 'svm':  # and model_params['kernel']=='linear') :\n",
    "            coeff = model.coef_.flatten()\n",
    "        else:\n",
    "            coeff = np.zeros(X.shape[1])\n",
    "\n",
    "        # process the predictions\n",
    "        pred_temp = pred.flatten()\n",
    "        # print \"pred_temp before descaling and decentering: \", pred_temp\n",
    "        if feature_selection != 'lda' and scaling:\n",
    "            pred_temp = descale_data(matrix=pred_temp, deviation=deviation, ddof=ddof)  # descale\n",
    "            pred_temp = pred_temp + mean  # add mean\n",
    "        elif feature_selection != 'lda':\n",
    "            pred_temp = pred_temp + mean\n",
    "        # print \"pred_temp after descaling and decentering: \", pred_temp\n",
    "        train_error = mean_squared_error(y_true=y_temp, y_pred=pred_temp)\n",
    "        fpr, tpr, auc = get_roc_auc(labels=y_temp, predictions=pred_temp)\n",
    "        pred_temp = round_num(pred_temp)\n",
    "\n",
    "        # AUC if needed\n",
    "\n",
    "        if verbose_train:\n",
    "            print \"Training error: \", train_error / num_samples\n",
    "            print \"Training error computed in library: \", train_error_temp\n",
    "            print \"Training auc: \", auc\n",
    "            plot_roc_curve(fpr, tpr, auc)\n",
    "        # print \"coefficients(betas?): \", coeff[:10]\n",
    "\n",
    "    return features, model, train_error, auc, coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_classifier(X, Y, subj, num_samples, mean, deviation, ddof, method, feature_selection, model_params,\n",
    "                      num_features, step, verbose_train, scaling):\n",
    "    # get original Y\n",
    "    if scaling:\n",
    "        Y_temp = np.array(Y)\n",
    "        Y_temp = descale_data(matrix=Y_temp, deviation=deviation, ddof=ddof)  # descale\n",
    "    Y_temp = Y + mean\n",
    "    Y_temp = round_num(Y_temp)\n",
    "\n",
    "    # perform the regression\n",
    "    model = PLSRegression(n_components=model_params['n_comp'], scale=False)  # initialize a generic PLS model\n",
    "    model.fit(X, Y)\n",
    "    pred = model.predict(X)  # predict the values on the train set\n",
    "\n",
    "    # handle the predictions\n",
    "    pred_temp = pred.flatten()\n",
    "    if scaling:\n",
    "        pred_temp = descale_data(matrix=pred_temp, deviation=deviation, ddof=ddof)  # descale\n",
    "    pred_temp = pred_temp + mean\n",
    "    # print \"Predictions before rounding in simple_classifier: \", pred_temp\n",
    "\n",
    "    train_error = mean_squared_error(y_true=Y_temp, y_pred=pred_temp)\n",
    "    fpr, tpr, auc = get_roc_auc(labels=Y_temp, predictions=pred_temp)  # AUC if needed\n",
    "\n",
    "    pred_temp = round_num(pred_temp)\n",
    "    # print \"Predictions after rounding in simple_classifier: \", pred_temp\n",
    "\n",
    "    return np.array(range(X.shape[1])), model, train_error, auc, model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_simple_classifier(X, Y, subj, ids, num_samples, mean, deviation, ddof, method, feature_selection,\n",
    "                                model_params,\n",
    "                                num_features, step, verbose_train, scaling, num_iter):\n",
    "    new_X = copy.copy(X)\n",
    "    new_features = np.array(range(X.shape[1]))\n",
    "    for i in range(num_iter):\n",
    "        __, model, train_error, auc, coeff = simple_classifier(X=new_X, Y=Y, subj=subj, num_samples=num_samples,\n",
    "                                                               mean=mean, deviation=deviation,\n",
    "                                                               ddof=ddof, method=method,\n",
    "                                                               feature_selection=feature_selection,\n",
    "                                                               model_params=model_params, num_features=num_features,\n",
    "                                                               step=step,\n",
    "                                                               verbose_train=verbose_train, scaling=scaling)\n",
    "        coefficients = np.zeros(X.shape[1])\n",
    "        count = 0\n",
    "        for k in range(X.shape[1]):\n",
    "            if k in new_features:\n",
    "                coefficients[k] = coeff[count]\n",
    "                count = count + 1\n",
    "        print \"Coefficients in iteration \"+str(i)+\" :\" +str(coefficients)\n",
    "\n",
    "        features = new_features\n",
    "        ix = np.array(np.argpartition(np.abs(coeff.reshape(np.shape(coeff)[0], )), int(np.rint(new_X.shape[1] / 2)))[\n",
    "                      -int(np.rint(new_X.shape[1] / 2)):])\n",
    "        new_features = features[ix]\n",
    "        new_X = X[:, new_features]\n",
    "    return features, model, train_error, auc, coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_num(numbers):\n",
    "    res = copy.copy(numbers)\n",
    "    for ix in range(len(numbers)):\n",
    "        if numbers[ix] >= 1:\n",
    "            res[ix] = 1\n",
    "        elif numbers[ix] <= 0:\n",
    "            res[ix] = 0\n",
    "        else:\n",
    "            res[ix] = np.rint(numbers[ix])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_data(matrix, mean=None):\n",
    "    if mean is None:\n",
    "        matrix = matrix - np.mean(a=matrix, axis=0)\n",
    "    else:\n",
    "        matrix = matrix - mean\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(matrix, deviation, ddof):\n",
    "    if deviation is None:\n",
    "        deviation = np.std(a=matrix, axis=0, ddof=ddof)\n",
    "    matrix_temp = copy.copy(matrix)\n",
    "    if np.isnan(matrix).any():\n",
    "        matrix = matrix_temp\n",
    "    elif np.count_nonzero(deviation) == 0:\n",
    "        matrix = matrix_temp\n",
    "    else:\n",
    "        matrix = matrix / deviation\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale_data(matrix, deviation, ddof):\n",
    "    if deviation is None:  # use the deviation from the same matrix to scale\n",
    "        matrix = matrix * np.std(a=matrix, axis=0, ddof=ddof)\n",
    "    else:  # use deviation given in parameters\n",
    "        matrix = matrix * deviation\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_auc(labels, predictions):\n",
    "    # compute precision-recall curve\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true=labels, y_score=predictions, drop_intermediate=False)\n",
    "    # compute area under the curve for this run\n",
    "    auc = metrics.roc_auc_score(y_true=labels, y_score=predictions, average='macro', sample_weight=None)\n",
    "    return fpr, tpr, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, auc):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTILEVEL PLS\n",
    "def perform_multilevel_pls(X, Y, subj, ids, unique_subj, num_unique_subj, num_subj, scaling, par, ddof, method,\n",
    "                           feature_selection, num_features, step, model_params, verbose_train, num_iter):\n",
    "    Xb = np.zeros(X.shape)\n",
    "    Xw = np.zeros(X.shape)\n",
    "\n",
    "    # mean-centering\n",
    "    X_centered = center_data(matrix=X, mean=None)  # mean centering of data\n",
    "    Y_centered = center_data(matrix=Y, mean=None)\n",
    "\n",
    "    # split matrix into between and within subject variations\n",
    "    if par != 'all':\n",
    "        Xb, Xw = split_between_within_subject_matrix(X=X_centered, subj=subj, unique_subj=unique_subj,\n",
    "                                                     num_unique_subj=num_unique_subj, num_subj=num_subj)\n",
    "\n",
    "    # scaling (if necessary and specified)\n",
    "    if scaling:  # scale the data, if the flag is true\n",
    "        X_scaled = scale_data(matrix=X_centered, deviation=None, ddof=ddof)\n",
    "        Y_scaled = scale_data(matrix=Y_centered, deviation=None, ddof=ddof)\n",
    "        if par != 'all':\n",
    "            Xb_scaled = scale_data(matrix=Xb, deviation=None, ddof=ddof)\n",
    "            Xw_scaled = scale_data(matrix=Xw, deviation=None, ddof=ddof)\n",
    "    else:\n",
    "        X_scaled = X_centered\n",
    "        Y_scaled = Y_centered\n",
    "        if par != 'all':\n",
    "            Xb_scaled = Xb\n",
    "            Xw_scaled = Xw\n",
    "\n",
    "    # which matrix are we interested in\n",
    "    if par == 'all':\n",
    "        X_target = X_scaled\n",
    "    elif par == 'between':\n",
    "        X_target = Xb_scaled\n",
    "    elif par == 'within':\n",
    "        X_target = Xw_scaled\n",
    "\n",
    "    # print \"X_target in perform_multilevel_pls: \", X_target\n",
    "\n",
    "    # perform classifier (PLS or other) on target data\n",
    "    # features, model, train_error, train_auc, coeff= classifier(X=X_target, Y=Y_scaled, subj=subj, num_samples=num_subj,\n",
    "    #                                                       mean=np.mean(Y), deviation= np.std(Y, axis=0, ddof=ddof), \n",
    "    #                                                       ddof=ddof, method=method, \n",
    "    #                                                       feature_selection=feature_selection, \n",
    "    #                                                       num_features=num_features, step=step, \n",
    "    #                                                       model_params=model_params, verbose_train=verbose_train, \n",
    "    #                                                       scaling=scaling)\n",
    "    #\n",
    "    #\n",
    "    features, model, train_error, train_auc, coeff = iterative_simple_classifier(X=X_target, Y=Y_scaled, subj=subj,\n",
    "                                                                                 ids=ids, num_samples=num_subj,\n",
    "                                                                                 mean=np.mean(Y),\n",
    "                                                                                 deviation=np.std(Y, axis=0, ddof=ddof),\n",
    "                                                                                 ddof=ddof, method=method,\n",
    "                                                                                 feature_selection=feature_selection,\n",
    "                                                                                 num_features=num_features, step=step,\n",
    "                                                                                 model_params=model_params,\n",
    "                                                                                 verbose_train=verbose_train,\n",
    "                                                                                 scaling=scaling, num_iter=num_iter)\n",
    "\n",
    "    # features, model, train_error, train_auc, coeff= simple_classifier(X=X_target, Y=Y_scaled, subj=subj, num_samples=num_subj,\n",
    "    #                                                       mean=np.mean(Y), deviation= np.std(Y, axis=0, ddof=ddof), \n",
    "    #                                                       ddof=ddof, method=method, \n",
    "    #                                                       feature_selection=feature_selection, \n",
    "    #                                                       num_features=num_features, step=step, \n",
    "    #                                                       model_params=model_params, verbose_train=verbose_train, \n",
    "    #                                                       scaling=scaling)\n",
    "    # print \"coeffs in perform_multilevel_pls: \", coeff[:10]\n",
    "\n",
    "    return features, model, train_error, train_auc, Xb, Xw, Y_scaled, X_scaled, coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_train_test(X, Y, subj, train_subj, test_subj, num_subj):\n",
    "    X_train = None  # initialization\n",
    "    X_test = None\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "    subj_train = []\n",
    "    subj_test = []\n",
    "\n",
    "    # create the test and train dataset from matrix X with chosen subjects\n",
    "    mask = np.isin(subj, train_subj)\n",
    "    inverse_mask = np.invert(mask)\n",
    "\n",
    "    subj_train = subj[mask]\n",
    "    subj_test = subj[inverse_mask]\n",
    "    X_train = X[mask]\n",
    "    Y_train = Y[mask]\n",
    "    X_test = X[inverse_mask]\n",
    "    Y_test = Y[inverse_mask]\n",
    "\n",
    "    num_train_subj = len(subj_train)  # how many entries in train dataset\n",
    "    num_test_subj = num_subj - num_train_subj  # how many entries in test dataset\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test, subj_train, subj_test, num_train_subj, num_test_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_script(num_folds, num_repeats, scaling, num_permutations, par, filename, verbose, ddof, method,\n",
    "                feature_selection, num_features, step, model_params, verbose_train, mode, num_iter, use_kf):\n",
    "    # READ OR MAKE UP DATA\n",
    "    X, Y, subj, IDs, NetCalc, frQ = read_data(filename, mode, use_kf)\n",
    "\n",
    "    # create list of unique subjects\n",
    "    unique_subj = np.unique(subj)\n",
    "    # the number of entries = number of subjects corresponding to entries (1 subject per entry)\n",
    "    num_subj = len(subj)\n",
    "    # the number of unique subjects\n",
    "    num_unique_subj = len(unique_subj)\n",
    "    # initialization of errors\n",
    "    error = 0\n",
    "    permutation_error = None\n",
    "    permutation_auc = None\n",
    "    permutation_Q = None\n",
    "    full_train_error = 0\n",
    "    full_train_auc = 0\n",
    "    crossval_error = 0\n",
    "    crossval_auc = 0\n",
    "    crossval_Q = 0\n",
    "    crossval_train_err = 0\n",
    "    crossval_train_auc = 0\n",
    "    crossval_R = 0\n",
    "    crossval_acc = 0\n",
    "    crossval_F = 0\n",
    "\n",
    "    # PERFORMING MULTILEVEL PLS ON WHOLE DATASET\n",
    "\n",
    "    features, full_model, full_train_error, full_train_auc, Xb, Xw, Y_scaled, X_scaled, coeff = perform_multilevel_pls(\n",
    "        X=X, Y=Y, subj=subj, ids=IDs,\n",
    "        unique_subj=unique_subj, num_subj=num_subj,\n",
    "        num_unique_subj=num_unique_subj, scaling=scaling, par=par,\n",
    "        ddof=ddof, method=method, feature_selection=feature_selection,\n",
    "        num_features=num_features, step=step, model_params=model_params, verbose_train=verbose_train, num_iter=num_iter)\n",
    "\n",
    "    if method == 'pls':\n",
    "        x = np.matmul(X_scaled[:, features], full_model.x_weights_[:, 0])\n",
    "        if full_model.x_weights_.shape[1]>2:\n",
    "            y = np.matmul(X_scaled[:, features], full_model.x_weights_[:, 1])\n",
    "        else:\n",
    "            y = np.ones(X_scaled.shape[0])\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.xlabel('PLS component 1')\n",
    "        plt.ylabel('PLS component 2')\n",
    "        colors = ['green', 'orange']\n",
    "        ax.scatter(x, y, c=Y)\n",
    "\n",
    "        fig.savefig(mode + \"_\" + str(model_params['n_comp']) + \"_\" + str(feature_selection) + '.png')  # save the figure to file\n",
    "        plt.close(fig)\n",
    "\n",
    "        # print \"new coefficients in full_script: \", coeff[:10]\n",
    "\n",
    "    if verbose:\n",
    "        print \"CROSS_VALIDATION ON ACTUAL DATA: \"\n",
    "\n",
    "    # CROSS-VALIDATION\n",
    "    crossval_error, crossval_auc, crossval_Q, crossval_R, crossval_acc, crossval_F, crossval_train_err, crossval_train_auc = cross_validation(\n",
    "        X=X, Y=Y,\n",
    "        subj=subj, ids=IDs, unique_subj=unique_subj, num_subj=num_subj, num_unique_subj=num_unique_subj,\n",
    "        num_folds=num_folds, num_repeats=num_repeats, scaling=scaling, par=par,\n",
    "        verbose=verbose, ddof=ddof, method=method, feature_selection=feature_selection,\n",
    "        num_features=num_features, step=step, model_params=model_params, verbose_train=verbose_train, num_iter=num_iter)\n",
    "    #\n",
    "    if verbose:\n",
    "        print \"PERMUTATED DATA CROSS_VALIDATION: \"\n",
    "\n",
    "    # PERMUTATE\n",
    "    permutation_error, permutation_auc, permutation_Q, permutation_train_error, permutation_train_auc = validate_permutation(\n",
    "        X=X, Y=Y, subj=subj,\n",
    "        ids=IDs,\n",
    "        unique_subj=unique_subj,\n",
    "        num_subj=num_subj,\n",
    "        num_unique_subj=num_unique_subj,\n",
    "        num_folds=num_folds,\n",
    "        num_repeats=num_repeats,\n",
    "        scaling=scaling,\n",
    "        num_permutations=num_permutations,\n",
    "        par=par, verbose=verbose,\n",
    "        ddof=ddof, method=method,\n",
    "        feature_selection=feature_selection,\n",
    "        num_features=num_features, step=step,\n",
    "        model_params=model_params,\n",
    "        verbose_train=verbose_train, num_iter=num_iter)\n",
    "\n",
    "    results = {'num_folds': num_folds, 'num_repeats': num_repeats, 'scaling': scaling,\n",
    "               'num_permutations': num_permutations,\n",
    "               'par': par, 'filename': filename, 'verbose': verbose, 'ddof': ddof, 'method': method,\n",
    "               'feature_selection': feature_selection, 'num_features': num_features, 'step': step,\n",
    "               'n_trees': model_params['n_trees'], 'max_depth': model_params['max_depth'],\n",
    "               'max_features': model_params['max_features'], 'min_samples_leaf': model_params['min_samples_leaf'],\n",
    "               'num_comp': model_params['n_comp'], 'full_train_error': full_train_error,\n",
    "               'full_train_auc': full_train_auc,\n",
    "               'crossval_error': crossval_error, 'crossval_auc': crossval_auc, 'crossval_Q': crossval_Q,\n",
    "               'crossval_R': crossval_R,\n",
    "               'crossval_acc': crossval_acc, 'crossval_F': crossval_F,\n",
    "               'crossval_train_err': crossval_train_err, 'crossval_train_auc': crossval_train_auc,\n",
    "               'permutation_error': permutation_error, 'permutation_auc': permutation_auc,\n",
    "               'permutation_Q': permutation_Q,\n",
    "               'C': model_params['C'], 'gamma': model_params['gamma'], 'epsilon': model_params['epsilon'],\n",
    "               'degree': model_params['degree'], 'kernel': model_params['kernel'], 'num_iter': num_iter,\n",
    "               'use_kf': use_kf}\n",
    "\n",
    "    return results, coeff, IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS-VALIDATION\n",
    "def cross_validation(X, Y, subj, ids, unique_subj, num_subj, num_unique_subj, num_folds, num_repeats, scaling, par,\n",
    "                     verbose, ddof, method, feature_selection, num_features, step, model_params,\n",
    "                     verbose_train, num_iter):\n",
    "    # initialization\n",
    "    error = 0\n",
    "    auc = 0\n",
    "    train_error = 0\n",
    "    train_auc = 0\n",
    "    acc = 0\n",
    "    R = 0\n",
    "    F = 0\n",
    "\n",
    "    # create array of labels for each subject\n",
    "    Y_temp = [Y[np.where(subj == unique_subj[i])[0][0]] for i in range(num_unique_subj)]\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    for i in range(num_repeats):\n",
    "        kf = StratifiedKFold(n_splits=num_folds)\n",
    "\n",
    "        for train_index, test_index in kf.split(X[:num_unique_subj], Y_temp):  # repeat with every fold as test set\n",
    "            train_subj = unique_subj[train_index]\n",
    "            test_subj = unique_subj[test_index]\n",
    "\n",
    "            X_train, X_test, Y_train, Y_test, subj_train, subj_test, num_train_subj, num_test_subj = separate_train_test(\n",
    "                X=X, Y=Y, subj=subj,\n",
    "                train_subj=train_subj,\n",
    "                test_subj=test_subj, num_subj=num_subj)\n",
    "\n",
    "            num_unique_train_subj = len(train_subj)\n",
    "            num_unique_test_subj = len(test_subj)\n",
    "\n",
    "            X_train_mean = np.mean(X_train, axis=0)\n",
    "            Y_train_mean = np.mean(Y_train, axis=0)\n",
    "\n",
    "            features, model, train_error_temp, train_auc_temp, Xb_train, Xw_train, Y_scaled_train, X_scaled_train, coeff = perform_multilevel_pls(\n",
    "                X=X_train, Y=Y_train, subj=subj_train, ids=ids,\n",
    "                unique_subj=train_subj,\n",
    "                num_unique_subj=num_unique_train_subj,\n",
    "                num_subj=num_train_subj, scaling=scaling, par=par,\n",
    "                ddof=ddof, method=method,\n",
    "                feature_selection=feature_selection,\n",
    "                num_features=num_features, step=step,\n",
    "                model_params=model_params,\n",
    "                verbose_train=verbose_train, num_iter=num_iter)\n",
    "\n",
    "            X_centered_test = center_data(X_test, X_train_mean)  # mean centering of data\n",
    "            Y_centered_test = center_data(Y_test, Y_train_mean)\n",
    "\n",
    "            # split test data into between and within subject variation\n",
    "            Xb_test, Xw_test = split_between_within_subject_matrix(X=X_centered_test, subj=subj_test,\n",
    "                                                                   unique_subj=test_subj,\n",
    "                                                                   num_unique_subj=num_unique_test_subj,\n",
    "                                                                   num_subj=num_test_subj)\n",
    "\n",
    "            if scaling:  # scale the data, if the flag is true\n",
    "                X_train_deviation = np.std(X_train, axis=0, ddof=ddof)\n",
    "                Y_train_deviation = np.std(Y_train, axis=0, ddof=ddof)\n",
    "                Xb_train_deviation = np.std(Xb_train, axis=0, ddof=ddof)\n",
    "                Xw_train_deviation = np.std(Xw_train, axis=0, ddof=ddof)\n",
    "\n",
    "                X_scaled_test = scale_data(matrix=X_centered_test, deviation=X_train_deviation, ddof=ddof)\n",
    "                Y_scaled_test = scale_data(matrix=Y_centered_test, deviation=Y_train_deviation, ddof=ddof)\n",
    "\n",
    "                Xb_scaled_test = scale_data(matrix=Xb_test, deviation=Xb_train_deviation, ddof=ddof)\n",
    "                Xw_scaled_test = scale_data(matrix=Xw_test, deviation=Xw_train_deviation, ddof=ddof)\n",
    "            else:\n",
    "\n",
    "                X_scaled_test = X_centered_test\n",
    "                Y_scaled_test = Y_centered_test\n",
    "                Xb_scaled_test = Xb_test\n",
    "                Xw_scaled_test = Xw_test\n",
    "\n",
    "            # if only between or only within subject variations chosen, predict on that part of the matrix\n",
    "            if par == 'all':\n",
    "                x_target = X_scaled_test\n",
    "            elif par == 'between':\n",
    "                x_target = Xb_scaled_test\n",
    "            elif par == 'within':\n",
    "                x_target = Xw_scaled_test\n",
    "            x_target = x_target[:, features]\n",
    "\n",
    "            if len(x_target.shape) == 3:\n",
    "                x_target = x_target.reshape(x_target.shape[0], x_target.shape[2])\n",
    "\n",
    "            pred = model.predict(x_target)  # predict test data with model trained on the training set\n",
    "\n",
    "            # process the predicted values\n",
    "            pred = pred.flatten()\n",
    "            pred = pred.reshape(np.product(pred.shape), )\n",
    "            pred = descale_data(matrix=pred, deviation=Y_train_deviation, ddof=ddof)\n",
    "            pred = pred + Y_train_mean\n",
    "            R_temp = r2_score(Y_test, pred)\n",
    "\n",
    "            pred_temp = round_num(pred)\n",
    "            acc_temp = accuracy_score(Y_test, pred_temp)\n",
    "            F_temp = f1_score(Y_test, pred_temp, average='macro')\n",
    "\n",
    "            # compute the cross-validation cumulative error (squeared error)\n",
    "            err_temp = mean_squared_error(y_true=Y_test, y_pred=pred)\n",
    "\n",
    "            # get and plot ROC curve, if want\n",
    "            fpr, tpr, auc_temp = get_roc_auc(labels=Y_test, predictions=pred)\n",
    "            if i % 10 == 0 and verbose:\n",
    "                plot_roc_curve(fpr=fpr, tpr=tpr, auc=auc_temp)\n",
    "\n",
    "            auc = auc + auc_temp\n",
    "            error = error + err_temp  # compute square error\n",
    "            train_error = train_error + train_error_temp\n",
    "            train_auc = train_auc + train_auc_temp\n",
    "            acc = acc + acc_temp\n",
    "            R = R + R_temp\n",
    "            F = F + F_temp\n",
    "\n",
    "    if num_repeats > 0:\n",
    "        R = R / (num_folds * num_repeats)\n",
    "        acc = acc / (num_folds * num_repeats)\n",
    "        F = F / (num_folds * num_repeats)\n",
    "        error = float(error) / (num_repeats * num_subj)  # mean error for cv\n",
    "        auc = auc / (num_repeats * num_folds)  # mean auc for cv\n",
    "        train_error = float(train_error) / (num_repeats * num_subj)  # mean train error for cv\n",
    "        train_auc = float(train_auc) / (num_repeats * num_folds)  # mean train auc for cv\n",
    "    Q = 1 - error / (sum(Y * Y) / float(num_subj))  # Q^2 metric\n",
    "    if verbose:\n",
    "        print \"Mean cross-validation error: \", error\n",
    "        print \"Mean cross-validation AUC: \", auc\n",
    "        print \"Cross-validation Q: \", Q\n",
    "    if verbose_train:\n",
    "        print \"Mean train cross-validation error: \", error\n",
    "        print \"Mean train cross-validation AUC: \", auc\n",
    "\n",
    "    return error, auc, Q, R, acc, F, train_error, train_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_between_within_subject_matrix(X, subj, unique_subj, num_unique_subj, num_subj):  # SPLIT MATRIX\n",
    "    Xb = np.zeros(X.shape)  # initialization\n",
    "    Xw = np.zeros(X.shape)\n",
    "    means = np.zeros((num_unique_subj, X.shape[1]))\n",
    "    for j in range(num_unique_subj):  # go through all unique subjects\n",
    "        # find indexes of all entries for a certain subject (unique_subj[j])\n",
    "        idx = np.where(np.array(subj) == unique_subj[j])\n",
    "        # calculate mean for each subject unique_subj[j]\n",
    "        means[j] = np.mean(X[idx[0]], axis=0)\n",
    "    for i in range(num_subj):  # go through subjects of all entries\n",
    "        # find the index of the subject corresponding to subj[i] in unique_subj\n",
    "        k = np.where(unique_subj == subj[i])\n",
    "        # create a matrix where all entries for subject = mean (between subject variation)\n",
    "        Xb[i] = means[k[0][0]]\n",
    "    Xw = X - Xb  # get the within subjects matrix\n",
    "    return Xb, Xw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERMUTATION\n",
    "def validate_permutation(X, Y, subj, ids, unique_subj, num_subj, num_unique_subj, num_folds, num_repeats, scaling,\n",
    "                         num_permutations, par, verbose, ddof, method, feature_selection, num_features,\n",
    "                         step, model_params, verbose_train, num_iter):\n",
    "    err = []  # initialization\n",
    "    auc = []\n",
    "    Q = []\n",
    "    train_err = []\n",
    "    train_auc = []\n",
    "\n",
    "    for i in range(num_permutations):  # perform permutations as many times as specified\n",
    "        Y_temp = Y.copy()  # create temporary labels which then shuffle/permutate, so original is left untouched\n",
    "\n",
    "        np.random.shuffle(Y_temp)  # randomly shuffle the Y(labels) vector. Checks if your results will be similar\n",
    "\n",
    "        # perform cross-validation for each permutation and get an array of accuracies when permutated\n",
    "        err_temp, auc_temp, Q_temp, train_error_temp, train_auc_temp = cross_validation(X=X, Y=Y_temp, subj=subj,\n",
    "                                                                                        ids=ids,\n",
    "                                                                                        unique_subj=unique_subj,\n",
    "                                                                                        num_subj=num_subj,\n",
    "                                                                                        num_unique_subj=num_unique_subj,\n",
    "                                                                                        num_folds=num_folds,\n",
    "                                                                                        num_repeats=num_repeats,\n",
    "                                                                                        scaling=scaling,\n",
    "                                                                                        par=par,\n",
    "                                                                                        verbose=verbose, ddof=ddof,\n",
    "                                                                                        method=method,\n",
    "                                                                                        feature_selection=feature_selection,\n",
    "                                                                                        num_features=num_features,\n",
    "                                                                                        step=step,\n",
    "                                                                                        model_params=model_params,\n",
    "                                                                                        verbose_train=verbose_train,\n",
    "                                                                                        num_iter=num_iter)\n",
    "\n",
    "        # save all the error and metrics values\n",
    "        err.append(err_temp)\n",
    "        auc.append(auc_temp)\n",
    "        Q.append(Q_temp)\n",
    "        train_err.append(train_err_temp)\n",
    "        train_auc.append(train_auc_temp)\n",
    "\n",
    "    if len(err) > 0 and verbose:\n",
    "        print \"Mean permutated squared error : \", np.mean(err)\n",
    "        print \"Mean permutated auc : \", np.mean(auc)\n",
    "        print \"Mean permutated Q: \", np.mean(Q)\n",
    "    elif verbose:\n",
    "        print \"No permutations performed\"\n",
    "    return err, auc, Q, train_err, train_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name=None, mode='delta1', use_kf=True):\n",
    "    if file_name is None:  # if no input file specified, make up data\n",
    "        num_subj = 30\n",
    "        num_feat = 1000\n",
    "        X_out = np.random.rand(num_subj, num_feat)\n",
    "        for i in range(3 * num_subj):\n",
    "            if i % 2 == 0:\n",
    "                X[i, 0] = X[i, 0] + (np.random.rand() + 0.75) * 15\n",
    "                X[i, 3] = X[i, 3] + (np.random.rand() + 0.75) * 20\n",
    "                X[i, 6] = X[i, 6] + (np.random.rand() + 0.75) * 17\n",
    "        Y = [1 if i % 2 == 0 else 0 for i in range(3 * num_subj)]\n",
    "        subjects = [1 + i % num_subj for i in range(3 * num_subj)]\n",
    "\n",
    "    else:\n",
    "        data = pd.read_excel(file_name)  # read the excel file\n",
    "\n",
    "        X = {}\n",
    "        subjects = {}\n",
    "        Y = {}\n",
    "        best_IDs = [123046, 117583, 86756, 133438, 83147, 126667, 172100, 142397, 120639, 120289, 156326, 122478,\n",
    "                    149189, 96777, 27106, 111945, 143274, 165258,\n",
    "                    131037, 157557, 116613, 124210, 141199, 116193, 104914, 157654, 138437, 136815, 145389, 126381,\n",
    "                    134480, 116092, 115231, 111308, 126611, 170398, 122508, 154395,\n",
    "                    70020, 114368, 111846, 115198, 118088, 111233, 112431, 129222, 123808, 88233, 140056, 98225, 129979,\n",
    "                    105895, 93554, 168699, 46429, 118641, 63581, 160205, 138660,\n",
    "                    143546, 106130, 160226, 120674, 117133, 136197, 150296, 150151, 172174, 91957, 49544, 46949, 66586,\n",
    "                    131636, 118862, 151173, 112437, 165739, 159266, 141582, 120258,\n",
    "                    121102, 141866, 122867, 120459, 108997, 158654, 116452, 138190, 87247, 123912, 111652, 57571,\n",
    "                    122104, 134658, 99130, 75234, 118373, 143395, 178875, 116969, 114194,\n",
    "                    143665, 135723, 123011, 143764, 139889, 99724, 123297, 173147, 99833, 45822, 127758, 105372, 129522,\n",
    "                    84139, 99759, 102071, 150305, 123324, 152526, 141850, 160588,\n",
    "                    157541, 112401, 109664, 75714, 77782, 61572, 158015, 108904, 158755, 150408, 99860, 136238, 116874,\n",
    "                    159126, 105832, 152891, 150153, 136635, 108399, 96311, 148861,\n",
    "                    41012, 135837, 166516, 161209, 92918, 111856, 117044, 126660, 81993, 118150, 102982, 147427, 60576,\n",
    "                    112635, 90322, 65937, 123300, 86897, 140036, 118805, 24102,\n",
    "                    81741, 120293, 152433, 114713, 130687, 116150, 15941, 41791, 156294, 149273, 166110, 84512, 117161,\n",
    "                    152638, 158804, 109189, 132854, 160162, 160580, 105321, 115801,\n",
    "                    86401, 94999, 143598, 115477, 114526, 23204, 94848, 89149, 117109, 126393, 105371, 76912, 151009,\n",
    "                    101847, 93456, 136303, 140721, 102537, 174794, 151593, 100728,\n",
    "                    101025, 120670, 114213, 117664, 83231, 158312, 147886, 106519, 116765, 126557, 62597, 116684,\n",
    "                    149030, 89192, 118560, 122442, 140495, 138780, 113328, 174883, 153224,\n",
    "                    147760, 144395, 129606, 140235, 138644, 94997, 98351, 95739, 142471, 106468, 125429, 165086, 98783,\n",
    "                    158277, 118568, 38745, 135112, 46468, 160346, 111272, 148683,\n",
    "                    97013, 72241, 96358, 129183, 106671, 124758, 93477, 160577, 76415, 171466, 144035, 142284, 137802,\n",
    "                    150517, 174979, 113884, 133553, 134644, 104612, 97056, 184329,\n",
    "                    144820, 145249, 157989, 109380, 125320, 161386, 134281, 108827, 86504, 134358, 134992, 106307,\n",
    "                    112171, 98538, 143145, 138484, 152261, 163107, 103372, 124782,\n",
    "                    156301, 93876, 101171, 161317, 147111, 175066, 167862, 93015, 98806, 129885, 132331, 91894, 156017,\n",
    "                    97581, 123087, 138061, 121029, 131804, 174279, 25378, 132130,\n",
    "                    170927, 120761, 33607, 136140, 159222, 110192, 101234, 29130, 119578, 185709, 88722, 118349, 139402,\n",
    "                    144127, 144007, 100418, 141075, 117573, 94215, 108871, 151299,\n",
    "                    134953, 94873, 133646, 124628, 169783, 133810, 106375, 147917, 126225, 120735, 107153, 175673,\n",
    "                    164989, 161732, 112685, 151337, 53126, 108345, 117812, 72767, 180769,\n",
    "                    137656, 88089, 134960, 173188, 148226, 53154, 81194, 114268, 118013, 153926, 70486, 89932, 143869,\n",
    "                    85974, 142786, 133451, 156972, 122803, 26440, 101797, 134826,\n",
    "                    54469, 109826, 152181, 91913, 98206, 103657, 95618, 157153, 93108, 145919, 64418, 120961, 74704,\n",
    "                    83051, 108622, 92065, 143847, 145817, 133631, 156253, 75611, 128156,\n",
    "                    133623, 99988, 114201, 103674, 96732, 133997, 146842, 111268, 114803, 156926, 156122, 112335,\n",
    "                    147223, 116388, 180201, 143287, 136217, 100764, 83709, 110274, 114684,\n",
    "                    148039, 57622, 121381, 115143, 132690, 144322, 125941, 61031, 192530, 144329, 56977, 153432, 151744,\n",
    "                    149525, 149649, 133929, 111905, 156284, 97619, 145408, 120259,\n",
    "                    145623, 176474, 145664, 114451, 84867, 117846, 78910, 173199, 114111, 136091, 132134, 102054,\n",
    "                    115738, 125532, 148528, 146956, 133430, 153530, 27836, 78839, 133993,\n",
    "                    144012, 179103, 55674, 79004, 56201, 110757, 124392, 109893, 120669, 141743, 140464, 133371, 156409,\n",
    "                    146587, 34067, 144914, 137624, 133737, 121614, 91437, 168924,\n",
    "                    94895, 105099, 157135, 83971, 123016, 125737, 134154, 128750, 153667, 111866, 103707, 144951,\n",
    "                    143689, 55564, 133992, 133826, 55040, 38860, 104326, 113384, 110631,\n",
    "                    151351, 156797, 169965, 41131, 149503, 116141, 122054, 172297, 118014, 103675, 172528, 69565,\n",
    "                    140558, 123793, 135131, 147353, 73158, 114199, 131956, 70656, 176937,\n",
    "                    102078, 133428]\n",
    "\n",
    "        loc = (file_name)\n",
    "\n",
    "        # To open Workbook\n",
    "        wb = xlrd.open_workbook(loc)\n",
    "        sheet = wb.sheet_by_index(0)\n",
    "\n",
    "        # For row 0 and column 0\n",
    "        IDs = np.array(sheet.col_values(3)[8:])\n",
    "        NetCalc = np.array(sheet.col_values(6)[8:])\n",
    "        frQ = np.array(sheet.col_values(9)[8:])\n",
    "        new_features = [IDs[ix] in best_IDs for ix in range(len(IDs))]\n",
    "\n",
    "        # take the matabolite matrix, transpose, convert to int\n",
    "        X['all'] = data.values[7:, :-9].transpose().astype(np.int64)\n",
    "        # take relevant values as labels, convert to int\n",
    "        Y['all'] = (data.head().iloc[-3].values[0:148] == 'risk').astype(np.int64)\n",
    "        # take relevant values as subject id's, convert to int\n",
    "        subjects['all'] = data.head().iloc[-2].values[0:148].astype(np.int64)\n",
    "\n",
    "        if use_kf:\n",
    "            X['all'] = X['all'][:, new_features]\n",
    "            IDs = best_IDs\n",
    "\n",
    "        unique_subj = np.unique(subjects['all'])\n",
    "        num_unique_subj = len(unique_subj)\n",
    "        num_subj = len(subjects['all'])\n",
    "        subj_time = {}\n",
    "        mask_temp = np.array([subjects['all'][index + 1] - subjects['all'][index] for index in range(num_subj - 1)])\n",
    "        lines = np.where(mask_temp < 0)[0]\n",
    "        X['delta1'] = []\n",
    "        X['delta2'] = []\n",
    "        X['delta3'] = []\n",
    "        subjects['delta1'] = []\n",
    "        subjects['delta2'] = []\n",
    "        subjects['delta3'] = []\n",
    "        Y['delta1'] = []\n",
    "        Y['delta2'] = []\n",
    "        Y['delta3'] = []\n",
    "        for s in unique_subj:\n",
    "            indeces_temp = np.where(subjects['all'] == s)[0]\n",
    "            subj_time[s] = {'t0': None, 't1': None, 't2': None}\n",
    "            for el in indeces_temp:\n",
    "                if el > lines[1]:\n",
    "                    subj_time[s]['t2'] = el\n",
    "                elif el <= lines[0]:\n",
    "                    subj_time[s]['t0'] = el\n",
    "                else:\n",
    "                    subj_time[s]['t1'] = el\n",
    "            if (subj_time[s]['t1'] is not None) and (subj_time[s]['t0'] is not None):\n",
    "                X_temp = (X['all'][subj_time[s]['t1']] - X['all'][subj_time[s]['t0']]).reshape(1, X['all'].shape[1])\n",
    "                X['delta1'].append(X_temp)\n",
    "                subjects['delta1'].append(s)\n",
    "                Y['delta1'].append(Y['all'][indeces_temp[0]])\n",
    "            if (subj_time[s]['t2'] is not None) and (subj_time[s]['t1'] is not None):\n",
    "                X_temp = (X['all'][subj_time[s]['t2']] - X['all'][subj_time[s]['t1']]).reshape(1, X['all'].shape[1])\n",
    "                X['delta2'].append(X_temp)\n",
    "                subjects['delta2'].append(s)\n",
    "                Y['delta2'].append(Y['all'][indeces_temp[0]])\n",
    "            if (subj_time[s]['t2'] is not None and subj_time[s]['t0'] is not None):\n",
    "                X_temp = (X['all'][subj_time[s]['t2']] - X['all'][subj_time[s]['t0']]).reshape(1, X['all'].shape[1])\n",
    "                X['delta3'].append(X_temp)\n",
    "                subjects['delta3'].append(s)\n",
    "                Y['delta3'].append(Y['all'][indeces_temp[0]])\n",
    "        X['delta1'] = np.vstack(X['delta1'])\n",
    "        X['delta2'] = np.vstack(X['delta2'])\n",
    "        X['delta3'] = np.vstack(X['delta3'])\n",
    "\n",
    "    return X[mode], np.array(Y[mode]), np.array(subjects[mode]), IDs, NetCalc, frQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-c C] [-eps EPSILON] [-ker KERNEL]\n",
      "                             [-gam GAMMA] [-deg DEGREE]\n",
      "                             [-fs FEATURE_SELECTION] [-step STEP]\n",
      "                             [-nfe NUM_FEATURES] [-v VERBOSE] [-m METHOD]\n",
      "                             [-vt VERBOSE_TRAIN] [-fn FILE_NAME] [-mtr MATRIX]\n",
      "                             [-nc NUM_COMP] [-nt NUM_TREES] [-md MAX_DEPTH]\n",
      "                             [-mf MAX_FEATURES] [-msl MIN_SAMPLES_LEAF]\n",
      "                             [-nr NUM_REPEATS] [-np NUM_PERMUTATIONS]\n",
      "                             [-nf NUM_FOLDS] [-sc SCALING] [-ddf DDOF]\n",
      "                             [-mod MODE] [-ni NUM_ITERATIONS]\n",
      "                             [-ukf USE_KIRILLS_FEATURES]\n",
      "ipykernel_launcher.py: error: ambiguous option: -f could match -fn, -fs\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# read params from command line\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-c\", dest=\"C\", default=1, type=float)\n",
    "parser.add_argument(\"-eps\", dest=\"epsilon\", default=0.1, type=float)\n",
    "parser.add_argument(\"-ker\", dest=\"kernel\", default='rbf')\n",
    "parser.add_argument(\"-gam\", dest=\"gamma\", default=0.0001, type=float)\n",
    "parser.add_argument(\"-deg\", dest=\"degree\", default=3, type=int)\n",
    "parser.add_argument(\"-fs\", dest=\"feature_selection\", default=None)\n",
    "parser.add_argument(\"-step\", dest=\"step\", default=0.3, type=float)\n",
    "parser.add_argument(\"-nfe\", dest=\"num_features\", default=0, type=int)\n",
    "parser.add_argument(\"-v\", dest=\"verbose\", default=False, type=bool)\n",
    "parser.add_argument(\"-m\", dest=\"method\", default='pls')\n",
    "parser.add_argument(\"-vt\", dest=\"verbose_train\", default=False, type=bool)\n",
    "parser.add_argument(\"-fn\", dest=\"file_name\", default='OGTT_INPUT.xlsx')\n",
    "parser.add_argument(\"-mtr\", dest=\"matrix\", default='between')\n",
    "parser.add_argument(\"-nc\", dest=\"num_comp\", default=2, type=int)\n",
    "parser.add_argument(\"-nt\", dest=\"num_trees\", default=200, type=int)\n",
    "parser.add_argument(\"-md\", dest=\"max_depth\", default=4, type=int)\n",
    "parser.add_argument(\"-mf\", dest=\"max_features\", default=1, type=int)\n",
    "parser.add_argument(\"-msl\", dest=\"min_samples_leaf\", default=1, type=int)\n",
    "parser.add_argument(\"-nr\", dest=\"num_repeats\", default=1, type=int)\n",
    "parser.add_argument(\"-np\", dest=\"num_permutations\", default=0, type=int)\n",
    "parser.add_argument(\"-nf\", dest=\"num_folds\", default=20, type=int)\n",
    "parser.add_argument(\"-sc\", dest=\"scaling\", default=True, type=bool)\n",
    "parser.add_argument(\"-ddf\", dest=\"ddof\", default=1, type=int)\n",
    "parser.add_argument(\"-mod\", dest=\"mode\", default='all')\n",
    "parser.add_argument(\"-ni\", dest=\"num_iterations\", default=1, type=int)\n",
    "parser.add_argument(\"-ukf\", dest=\"use_kirills_features\", default=False, type=bool)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# run script with parameters\n",
    "results = []\n",
    "\n",
    "model_params = {}\n",
    "for mod in ['rf', 'svm', 'pls', 'lda', 'nn']:\n",
    "    model_params[mod] = {}\n",
    "    model_params[mod]['n_trees'] = None\n",
    "    model_params[mod]['max_depth'] = None\n",
    "    model_params[mod]['max_features'] = None\n",
    "    model_params[mod]['min_samples_leaf'] = None\n",
    "    model_params[mod]['C'] = None\n",
    "    model_params[mod]['epsilon'] = None\n",
    "    model_params[mod]['kernel'] = None\n",
    "    model_params[mod]['gamma'] = None\n",
    "    model_params[mod]['degree'] = None\n",
    "    model_params[mod]['n_comp'] = None\n",
    "\n",
    "model_params['rf']['n_trees'] = args.num_trees\n",
    "model_params['rf']['max_depth'] = args.max_depth\n",
    "model_params['rf']['max_features'] = args.max_features\n",
    "model_params['rf']['min_samples_leaf'] = args.min_samples_leaf\n",
    "model_params['svm']['C'] = args.C\n",
    "model_params['svm']['epsilon'] = args.epsilon\n",
    "model_params['svm']['kernel'] = args.kernel\n",
    "model_params['svm']['gamma'] = args.gamma\n",
    "model_params['svm']['degree'] = args.degree\n",
    "model_params['pls']['n_comp'] = args.num_comp\n",
    "model_params['lda']['n_comp'] = args.num_comp\n",
    "\n",
    "#betas = {'all':[], 'delta1':[], 'delta2':[], 'delta3':[], 'within':[], 'between':[], 'ID':[]}\n",
    "#modes = ['delta1', 'all', 'between', 'within', 'delta2', 'delta3']\n",
    "modes = ['delta1']\n",
    "betas = {'delta1': []}\n",
    "#modes = ['delta1', 'delta2', 'delta3']\n",
    "#betas = {'delta1': [], 'delta2':[], 'delta3':[]}\n",
    "\n",
    "num_iterations = [1, 2, 3, 4, 5]\n",
    "num_components = [2]\n",
    "#num_iterations = [1, 2, 3, 4, 5, 6, 7]\n",
    "#num_components = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "#args.use_kirills_features = True\n",
    "# epsilons = [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "# c_values = [1, 10, 100, 1000, 10000, 100000]\n",
    "for ni in num_iterations:\n",
    "    for nc in num_components:\n",
    "        args.num_iterations = ni\n",
    "        model_params['pls']['n_comp'] = nc\n",
    "        for m in modes:\n",
    "            if m == 'all':\n",
    "                args.matrix = 'all'\n",
    "                args.mode = 'all'\n",
    "            elif m == 'between':\n",
    "                args.matrix = 'between'\n",
    "                args.mode = 'all'\n",
    "            elif m == 'within':\n",
    "                args.matrix = 'within'\n",
    "                args.mode = 'all'\n",
    "            else:\n",
    "                args.mode = m\n",
    "                args.matrix = 'all'\n",
    "\n",
    "            results_temp, coef, IDs = full_script(args.num_folds, args.num_repeats, args.scaling, args.num_permutations,\n",
    "                                                  args.matrix, args.file_name, args.verbose, args.ddof, args.method,\n",
    "                                                  args.feature_selection, args.num_features, args.step,\n",
    "                                                  model_params[args.method], args.verbose_train, args.mode,\n",
    "                                                  args.num_iterations, args.use_kirills_features)\n",
    "            results_temp['mode'] = m\n",
    "            print \"Results: \", results_temp\n",
    "            betas[m] = coef\n",
    "            sys.stdout.flush()\n",
    "            results.append(results_temp)\n",
    "\n",
    "        betas_t = betas\n",
    "        betas_t['ID'] = IDs\n",
    "\n",
    "        dest_file = \"coef_pls_\" + str(model_params['pls']['n_comp']) + \"_\"+str(args.num_iterations)+\".csv\"\n",
    "        with open(dest_file, 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(betas_t.keys())\n",
    "            writer.writerows(zip(*betas_t.values()))  # .sort(key = lambda t: t[1]))\n",
    "\n",
    "res_file = \"res2_\" + args.method + \"_\" + str(args.num_features) + \"_\" + str(args.feature_selection) + \"_\" + str(\n",
    "            args.step) +\".csv\"\n",
    "\n",
    "with open(res_file, 'w') as csvfile:\n",
    "    fieldnames = ['crossval_auc', 'crossval_error', 'crossval_Q', 'crossval_train_auc', 'crossval_train_err',\n",
    "                  'method', 'feature_selection', 'num_features', 'step', 'n_trees', 'max_depth', 'max_features',\n",
    "                  'num_comp', 'C', 'epsilon', 'kernel', 'gamma', 'degree', 'mode', 'num_iter', 'crossval_F',\n",
    "                  'crossval_R', 'use_kf']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for r in results:\n",
    "        results_t = {your_key: r[your_key] for your_key in fieldnames}\n",
    "        writer.writerow(results_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[ 0 49 98]\n",
      "{'t2': 98, 't0': 0, 't1': 49}\n",
      "(8382L,)\n",
      "[      0       0 2358746 ...       0       0       0]\n",
      "After 1 if for subject 1\n",
      "After 2 if for subject 1\n",
      "After 3 if for subject 1\n",
      "After 4 if for subject 1\n",
      "After 5 if for subject 1\n",
      "After 6 if for subject 1\n",
      "2\n",
      "[ 1 50 99]\n",
      "{'t2': 99, 't0': 1, 't1': 50}\n",
      "(8382L,)\n",
      "[      0       0 2362052 ... 4215467       0       0]\n",
      "After 1 if for subject 2\n",
      "After 2 if for subject 2\n",
      "After 3 if for subject 2\n",
      "After 4 if for subject 2\n",
      "After 5 if for subject 2\n",
      "After 6 if for subject 2\n",
      "3\n",
      "[  2  51 100]\n",
      "{'t2': 100, 't0': 2, 't1': 51}\n",
      "(8382L,)\n",
      "[1749142       0 4028075 ...       0       0       0]\n",
      "After 1 if for subject 3\n",
      "After 2 if for subject 3\n",
      "After 3 if for subject 3\n",
      "After 4 if for subject 3\n",
      "After 5 if for subject 3\n",
      "After 6 if for subject 3\n",
      "4\n",
      "[  3  52 101]\n",
      "{'t2': 101, 't0': 3, 't1': 52}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 4\n",
      "After 2 if for subject 4\n",
      "After 3 if for subject 4\n",
      "After 4 if for subject 4\n",
      "After 5 if for subject 4\n",
      "After 6 if for subject 4\n",
      "5\n",
      "[  4  53 102]\n",
      "{'t2': 102, 't0': 4, 't1': 53}\n",
      "(8382L,)\n",
      "[      0       0 1787163 ...       0       0       0]\n",
      "After 1 if for subject 5\n",
      "After 2 if for subject 5\n",
      "After 3 if for subject 5\n",
      "After 4 if for subject 5\n",
      "After 5 if for subject 5\n",
      "After 6 if for subject 5\n",
      "6\n",
      "[  5  54 103]\n",
      "{'t2': 103, 't0': 5, 't1': 54}\n",
      "(8382L,)\n",
      "[      0       0       0 ... 4321904       0       0]\n",
      "After 1 if for subject 6\n",
      "After 2 if for subject 6\n",
      "After 3 if for subject 6\n",
      "After 4 if for subject 6\n",
      "After 5 if for subject 6\n",
      "After 6 if for subject 6\n",
      "7\n",
      "[  6  55 104]\n",
      "{'t2': 104, 't0': 6, 't1': 55}\n",
      "(8382L,)\n",
      "[      0       0 3192133 ...       0 7561503       0]\n",
      "After 1 if for subject 7\n",
      "After 2 if for subject 7\n",
      "After 3 if for subject 7\n",
      "After 4 if for subject 7\n",
      "After 5 if for subject 7\n",
      "After 6 if for subject 7\n",
      "8\n",
      "[  7  56 105]\n",
      "{'t2': 105, 't0': 7, 't1': 56}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 8\n",
      "After 2 if for subject 8\n",
      "After 3 if for subject 8\n",
      "After 4 if for subject 8\n",
      "After 5 if for subject 8\n",
      "After 6 if for subject 8\n",
      "10\n",
      "[  8  57 106]\n",
      "{'t2': 106, 't0': 8, 't1': 57}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 10\n",
      "After 2 if for subject 10\n",
      "After 3 if for subject 10\n",
      "After 4 if for subject 10\n",
      "After 5 if for subject 10\n",
      "After 6 if for subject 10\n",
      "11\n",
      "[  9  58 107]\n",
      "{'t2': 107, 't0': 9, 't1': 58}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 11\n",
      "After 2 if for subject 11\n",
      "After 3 if for subject 11\n",
      "After 4 if for subject 11\n",
      "After 5 if for subject 11\n",
      "After 6 if for subject 11\n",
      "12\n",
      "[ 10  59 108]\n",
      "{'t2': 108, 't0': 10, 't1': 59}\n",
      "(8382L,)\n",
      "[      0       0 2398392 ...       0       0       0]\n",
      "After 1 if for subject 12\n",
      "After 2 if for subject 12\n",
      "After 3 if for subject 12\n",
      "After 4 if for subject 12\n",
      "After 5 if for subject 12\n",
      "After 6 if for subject 12\n",
      "13\n",
      "[ 11  60 109]\n",
      "{'t2': 109, 't0': 11, 't1': 60}\n",
      "(8382L,)\n",
      "[      0       0       0 ... 3840228       0       0]\n",
      "After 1 if for subject 13\n",
      "After 2 if for subject 13\n",
      "After 3 if for subject 13\n",
      "After 4 if for subject 13\n",
      "After 5 if for subject 13\n",
      "After 6 if for subject 13\n",
      "14\n",
      "[ 12  61 110]\n",
      "{'t2': 110, 't0': 12, 't1': 61}\n",
      "(8382L,)\n",
      "[       0        0  6267183 ...        0 11162586        0]\n",
      "After 1 if for subject 14\n",
      "After 2 if for subject 14\n",
      "After 3 if for subject 14\n",
      "After 4 if for subject 14\n",
      "After 5 if for subject 14\n",
      "After 6 if for subject 14\n",
      "15\n",
      "[ 13  62 111]\n",
      "{'t2': 111, 't0': 13, 't1': 62}\n",
      "(8382L,)\n",
      "[      0       0 2497185 ...       0       0       0]\n",
      "After 1 if for subject 15\n",
      "After 2 if for subject 15\n",
      "After 3 if for subject 15\n",
      "After 4 if for subject 15\n",
      "After 5 if for subject 15\n",
      "After 6 if for subject 15\n",
      "16\n",
      "[ 14  63 112]\n",
      "{'t2': 112, 't0': 14, 't1': 63}\n",
      "(8382L,)\n",
      "[3986455       0       0 ...       0       0       0]\n",
      "After 1 if for subject 16\n",
      "After 2 if for subject 16\n",
      "After 3 if for subject 16\n",
      "After 4 if for subject 16\n",
      "After 5 if for subject 16\n",
      "After 6 if for subject 16\n",
      "17\n",
      "[ 15  64 113]\n",
      "{'t2': 113, 't0': 15, 't1': 64}\n",
      "(8382L,)\n",
      "[       0  1659974  2041978 ...        0 11594607        0]\n",
      "After 1 if for subject 17\n",
      "After 2 if for subject 17\n",
      "After 3 if for subject 17\n",
      "After 4 if for subject 17\n",
      "After 5 if for subject 17\n",
      "After 6 if for subject 17\n",
      "18\n",
      "[ 16  65 114]\n",
      "{'t2': 114, 't0': 16, 't1': 65}\n",
      "(8382L,)\n",
      "[      0       0       0 ... 4693180       0       0]\n",
      "After 1 if for subject 18\n",
      "After 2 if for subject 18\n",
      "After 3 if for subject 18\n",
      "After 4 if for subject 18\n",
      "After 5 if for subject 18\n",
      "After 6 if for subject 18\n",
      "19\n",
      "[ 17  66 115]\n",
      "{'t2': 115, 't0': 17, 't1': 66}\n",
      "(8382L,)\n",
      "[      0       0 2348848 ... 5620880 3465104       0]\n",
      "After 1 if for subject 19\n",
      "After 2 if for subject 19\n",
      "After 3 if for subject 19\n",
      "After 4 if for subject 19\n",
      "After 5 if for subject 19\n",
      "After 6 if for subject 19\n",
      "20\n",
      "[ 18  67 116]\n",
      "{'t2': 116, 't0': 18, 't1': 67}\n",
      "(8382L,)\n",
      "[5337430       0 6062190 ...       0       0       0]\n",
      "After 1 if for subject 20\n",
      "After 2 if for subject 20\n",
      "After 3 if for subject 20\n",
      "After 4 if for subject 20\n",
      "After 5 if for subject 20\n",
      "After 6 if for subject 20\n",
      "21\n",
      "[ 19  68 117]\n",
      "{'t2': 117, 't0': 19, 't1': 68}\n",
      "(8382L,)\n",
      "[       0  2294365  3465735 ...        0 15058650        0]\n",
      "After 1 if for subject 21\n",
      "After 2 if for subject 21\n",
      "After 3 if for subject 21\n",
      "After 4 if for subject 21\n",
      "After 5 if for subject 21\n",
      "After 6 if for subject 21\n",
      "22\n",
      "[ 20  69 118]\n",
      "{'t2': 118, 't0': 20, 't1': 69}\n",
      "(8382L,)\n",
      "[      0       0 3394992 ... 3265942       0       0]\n",
      "After 1 if for subject 22\n",
      "After 2 if for subject 22\n",
      "After 3 if for subject 22\n",
      "After 4 if for subject 22\n",
      "After 5 if for subject 22\n",
      "After 6 if for subject 22\n",
      "23\n",
      "[ 21  70 119]\n",
      "{'t2': 119, 't0': 21, 't1': 70}\n",
      "(8382L,)\n",
      "[      0       0 4966310 ...       0 4437468       0]\n",
      "After 1 if for subject 23\n",
      "After 2 if for subject 23\n",
      "After 3 if for subject 23\n",
      "After 4 if for subject 23\n",
      "After 5 if for subject 23\n",
      "After 6 if for subject 23\n",
      "24\n",
      "[ 22  71 120]\n",
      "{'t2': 120, 't0': 22, 't1': 71}\n",
      "(8382L,)\n",
      "[      0       0 2023100 ...       0 8838260       0]\n",
      "After 1 if for subject 24\n",
      "After 2 if for subject 24\n",
      "After 3 if for subject 24\n",
      "After 4 if for subject 24\n",
      "After 5 if for subject 24\n",
      "After 6 if for subject 24\n",
      "25\n",
      "[ 72 121]\n",
      "{'t2': 121, 't0': None, 't1': 72}\n",
      "(8382L,)\n",
      "[1700822       0       0 ...       0       0       0]\n",
      "After 1 if for subject 25\n",
      "After 2 if for subject 25\n",
      "After 3 if for subject 25\n",
      "After 4 if for subject 25\n",
      "After 5 if for subject 25\n",
      "After 6 if for subject 25\n",
      "26\n",
      "[ 23  73 122]\n",
      "{'t2': 122, 't0': 23, 't1': 73}\n",
      "(8382L,)\n",
      "[      0       0       0 ... 3615035 4190364 4209475]\n",
      "After 1 if for subject 26\n",
      "After 2 if for subject 26\n",
      "After 3 if for subject 26\n",
      "After 4 if for subject 26\n",
      "After 5 if for subject 26\n",
      "After 6 if for subject 26\n",
      "27\n",
      "[ 24  74 123]\n",
      "{'t2': 123, 't0': 24, 't1': 74}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 27\n",
      "After 2 if for subject 27\n",
      "After 3 if for subject 27\n",
      "After 4 if for subject 27\n",
      "After 5 if for subject 27\n",
      "After 6 if for subject 27\n",
      "28\n",
      "[ 25  75 124]\n",
      "{'t2': 124, 't0': 25, 't1': 75}\n",
      "(8382L,)\n",
      "[2110618 1585556       0 ...       0       0       0]\n",
      "After 1 if for subject 28\n",
      "After 2 if for subject 28\n",
      "After 3 if for subject 28\n",
      "After 4 if for subject 28\n",
      "After 5 if for subject 28\n",
      "After 6 if for subject 28\n",
      "29\n",
      "[ 26  76 125]\n",
      "{'t2': 125, 't0': 26, 't1': 76}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 29\n",
      "After 2 if for subject 29\n",
      "After 3 if for subject 29\n",
      "After 4 if for subject 29\n",
      "After 5 if for subject 29\n",
      "After 6 if for subject 29\n",
      "30\n",
      "[ 27  77 126]\n",
      "{'t2': 126, 't0': 27, 't1': 77}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 30\n",
      "After 2 if for subject 30\n",
      "After 3 if for subject 30\n",
      "After 4 if for subject 30\n",
      "After 5 if for subject 30\n",
      "After 6 if for subject 30\n",
      "31\n",
      "[ 28  78 127]\n",
      "{'t2': 127, 't0': 28, 't1': 78}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 31\n",
      "After 2 if for subject 31\n",
      "After 3 if for subject 31\n",
      "After 4 if for subject 31\n",
      "After 5 if for subject 31\n",
      "After 6 if for subject 31\n",
      "32\n",
      "[ 29  79 128]\n",
      "{'t2': 128, 't0': 29, 't1': 79}\n",
      "(8382L,)\n",
      "[      0       0 3520734 ... 5782690       0       0]\n",
      "After 1 if for subject 32\n",
      "After 2 if for subject 32\n",
      "After 3 if for subject 32\n",
      "After 4 if for subject 32\n",
      "After 5 if for subject 32\n",
      "After 6 if for subject 32\n",
      "33\n",
      "[ 30  80 129]\n",
      "{'t2': 129, 't0': 30, 't1': 80}\n",
      "(8382L,)\n",
      "[       0        0        0 ... 13612525        0        0]\n",
      "After 1 if for subject 33\n",
      "After 2 if for subject 33\n",
      "After 3 if for subject 33\n",
      "After 4 if for subject 33\n",
      "After 5 if for subject 33\n",
      "After 6 if for subject 33\n",
      "34\n",
      "[ 31  81 130]\n",
      "{'t2': 130, 't0': 31, 't1': 81}\n",
      "(8382L,)\n",
      "[2528183       0       0 ... 3578611       0       0]\n",
      "After 1 if for subject 34\n",
      "After 2 if for subject 34\n",
      "After 3 if for subject 34\n",
      "After 4 if for subject 34\n",
      "After 5 if for subject 34\n",
      "After 6 if for subject 34\n",
      "35\n",
      "[ 32  82 131]\n",
      "{'t2': 131, 't0': 32, 't1': 82}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 35\n",
      "After 2 if for subject 35\n",
      "After 3 if for subject 35\n",
      "After 4 if for subject 35\n",
      "After 5 if for subject 35\n",
      "After 6 if for subject 35\n",
      "36\n",
      "[ 33  83 132]\n",
      "{'t2': 132, 't0': 33, 't1': 83}\n",
      "(8382L,)\n",
      "[      0 1708093       0 ...       0       0       0]\n",
      "After 1 if for subject 36\n",
      "After 2 if for subject 36\n",
      "After 3 if for subject 36\n",
      "After 4 if for subject 36\n",
      "After 5 if for subject 36\n",
      "After 6 if for subject 36\n",
      "37\n",
      "[ 34  84 133]\n",
      "{'t2': 133, 't0': 34, 't1': 84}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 37\n",
      "After 2 if for subject 37\n",
      "After 3 if for subject 37\n",
      "After 4 if for subject 37\n",
      "After 5 if for subject 37\n",
      "After 6 if for subject 37\n",
      "38\n",
      "[ 35  85 134]\n",
      "{'t2': 134, 't0': 35, 't1': 85}\n",
      "(8382L,)\n",
      "[      0       0 2482392 ...       0       0       0]\n",
      "After 1 if for subject 38\n",
      "After 2 if for subject 38\n",
      "After 3 if for subject 38\n",
      "After 4 if for subject 38\n",
      "After 5 if for subject 38\n",
      "After 6 if for subject 38\n",
      "39\n",
      "[ 36  86 135]\n",
      "{'t2': 135, 't0': 36, 't1': 86}\n",
      "(8382L,)\n",
      "[      0       0 1751915 ...       0       0       0]\n",
      "After 1 if for subject 39\n",
      "After 2 if for subject 39\n",
      "After 3 if for subject 39\n",
      "After 4 if for subject 39\n",
      "After 5 if for subject 39\n",
      "After 6 if for subject 39\n",
      "40\n",
      "[ 37  87 136]\n",
      "{'t2': 136, 't0': 37, 't1': 87}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 40\n",
      "After 2 if for subject 40\n",
      "After 3 if for subject 40\n",
      "After 4 if for subject 40\n",
      "After 5 if for subject 40\n",
      "After 6 if for subject 40\n",
      "41\n",
      "[ 38  88 137]\n",
      "{'t2': 137, 't0': 38, 't1': 88}\n",
      "(8382L,)\n",
      "[2491235       0 2298068 ...       0       0       0]\n",
      "After 1 if for subject 41\n",
      "After 2 if for subject 41\n",
      "After 3 if for subject 41\n",
      "After 4 if for subject 41\n",
      "After 5 if for subject 41\n",
      "After 6 if for subject 41\n",
      "42\n",
      "[ 39  89 138]\n",
      "{'t2': 138, 't0': 39, 't1': 89}\n",
      "(8382L,)\n",
      "[2139838       0 4045125 ... 4792288       0       0]\n",
      "After 1 if for subject 42\n",
      "After 2 if for subject 42\n",
      "After 3 if for subject 42\n",
      "After 4 if for subject 42\n",
      "After 5 if for subject 42\n",
      "After 6 if for subject 42\n",
      "43\n",
      "[ 40  90 139]\n",
      "{'t2': 139, 't0': 40, 't1': 90}\n",
      "(8382L,)\n",
      "[1656041       0 1671334 ...       0       0       0]\n",
      "After 1 if for subject 43\n",
      "After 2 if for subject 43\n",
      "After 3 if for subject 43\n",
      "After 4 if for subject 43\n",
      "After 5 if for subject 43\n",
      "After 6 if for subject 43\n",
      "46\n",
      "[ 41  91 140]\n",
      "{'t2': 140, 't0': 41, 't1': 91}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 46\n",
      "After 2 if for subject 46\n",
      "After 3 if for subject 46\n",
      "After 4 if for subject 46\n",
      "After 5 if for subject 46\n",
      "After 6 if for subject 46\n",
      "47\n",
      "[ 42  92 141]\n",
      "{'t2': 141, 't0': 42, 't1': 92}\n",
      "(8382L,)\n",
      "[1663527       0 4320625 ...       0 5166404       0]\n",
      "After 1 if for subject 47\n",
      "After 2 if for subject 47\n",
      "After 3 if for subject 47\n",
      "After 4 if for subject 47\n",
      "After 5 if for subject 47\n",
      "After 6 if for subject 47\n",
      "49\n",
      "[ 43  93 142]\n",
      "{'t2': 142, 't0': 43, 't1': 93}\n",
      "(8382L,)\n",
      "[      0       0       0 ... 3594399       0 3405925]\n",
      "After 1 if for subject 49\n",
      "After 2 if for subject 49\n",
      "After 3 if for subject 49\n",
      "After 4 if for subject 49\n",
      "After 5 if for subject 49\n",
      "After 6 if for subject 49\n",
      "50\n",
      "[ 44  94 143]\n",
      "{'t2': 143, 't0': 44, 't1': 94}\n",
      "(8382L,)\n",
      "[      0       0 2911766 ...       0       0       0]\n",
      "After 1 if for subject 50\n",
      "After 2 if for subject 50\n",
      "After 3 if for subject 50\n",
      "After 4 if for subject 50\n",
      "After 5 if for subject 50\n",
      "After 6 if for subject 50\n",
      "51\n",
      "[ 45  95 144]\n",
      "{'t2': 144, 't0': 45, 't1': 95}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 51\n",
      "After 2 if for subject 51\n",
      "After 3 if for subject 51\n",
      "After 4 if for subject 51\n",
      "After 5 if for subject 51\n",
      "After 6 if for subject 51\n",
      "53\n",
      "[ 46 145]\n",
      "{'t2': 145, 't0': 46, 't1': None}\n",
      "(1L, 148L, 8382L)\n",
      "[[[      0       0 2846782 ...       0       0       0]\n",
      "  [      0       0 2384802 ...       0 8276174 6375419]\n",
      "  [      0 2029981 2014578 ...       0 4433480 6715972]\n",
      "  ...\n",
      "  [      0       0 1945081 ...       0       0 4773428]\n",
      "  [      0       0       0 ...       0       0       0]\n",
      "  [      0       0       0 ... 7368900       0       0]]]\n",
      "After 1 if for subject 53\n",
      "After 2 if for subject 53\n",
      "After 3 if for subject 53\n",
      "After 4 if for subject 53\n",
      "After 5 if for subject 53\n",
      "After 6 if for subject 53\n",
      "54\n",
      "[ 47  96 146]\n",
      "{'t2': 146, 't0': 47, 't1': 96}\n",
      "(8382L,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "After 1 if for subject 54\n",
      "After 2 if for subject 54\n",
      "After 3 if for subject 54\n",
      "After 4 if for subject 54\n",
      "After 5 if for subject 54\n",
      "After 6 if for subject 54\n",
      "55\n",
      "[ 48  97 147]\n",
      "{'t2': 147, 't0': 48, 't1': 97}\n",
      "(8382L,)\n",
      "[      0 1689302       0 ...       0       0       0]\n",
      "After 1 if for subject 55\n",
      "After 2 if for subject 55\n",
      "After 3 if for subject 55\n",
      "After 4 if for subject 55\n",
      "After 5 if for subject 55\n",
      "After 6 if for subject 55\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "file_name = 'OGTT_INPUT.xlsx'\n",
    "data = pd.read_excel(file_name)  # read the excel file\n",
    "X = {}\n",
    "subjects = {}\n",
    "Y = {}\n",
    "loc = (file_name)\n",
    "\n",
    "# To open Workbook\n",
    "wb = xlrd.open_workbook(loc)\n",
    "sheet = wb.sheet_by_index(0)\n",
    "\n",
    "# For row 0 and column 0\n",
    "IDs = np.array(sheet.col_values(3)[8:])\n",
    "NetCalc = np.array(sheet.col_values(6)[8:])\n",
    "frQ = np.array(sheet.col_values(9)[8:])\n",
    "\n",
    "# take the matabolite matrix, transpose, convert to int\n",
    "X['all'] = data.values[7:, :-9].transpose().astype(np.int64)\n",
    "# take relevant values as labels, convert to int\n",
    "Y['all'] = (data.head().iloc[-3].values[0:148] == 'risk').astype(np.int64)\n",
    "# take relevant values as subject id's, convert to int\n",
    "subjects['all'] = data.head().iloc[-2].values[0:148].astype(np.int64)\n",
    "unique_subj = np.unique(subjects['all'])\n",
    "num_unique_subj = len(unique_subj)\n",
    "num_subj = len(subjects['all'])\n",
    "subj_time = {}\n",
    "mask_temp = np.array([subjects['all'][index + 1] - subjects['all'][index] for index in range(num_subj - 1)])\n",
    "lines = np.where(mask_temp < 0)[0]\n",
    "X['delta1'] = []\n",
    "X['delta2'] = []\n",
    "X['delta3'] = []\n",
    "subjects['delta1'] = []\n",
    "subjects['delta2'] = []\n",
    "subjects['delta3'] = []\n",
    "Y['delta1'] = []\n",
    "Y['delta2'] = []\n",
    "Y['delta3'] = []\n",
    "X['t1'] = []\n",
    "X['t2'] = []\n",
    "X['t0'] = []\n",
    "subjects['t1'] = []\n",
    "subjects['t2'] = []\n",
    "subjects['t0'] = []\n",
    "Y['t1'] = []\n",
    "Y['t2'] = []\n",
    "Y['t0'] = []\n",
    "\n",
    "for s in unique_subj:\n",
    "    print s\n",
    "    indeces_temp = np.where(subjects['all'] == s)[0]\n",
    "    print indeces_temp\n",
    "    subj_time[s] = {'t0': None, 't1': None, 't2': None}\n",
    "    for el in indeces_temp:\n",
    "        if el > lines[1]:\n",
    "            subj_time[s]['t2'] = el\n",
    "        elif el <= lines[0]:\n",
    "            subj_time[s]['t0'] = el\n",
    "        else:\n",
    "            subj_time[s]['t1'] = el\n",
    "    print subj_time[s]\n",
    "    print X['all'][subj_time[s]['t1']].shape\n",
    "    print X['all'][subj_time[s]['t1']]\n",
    "    if (subj_time[s]['t1'] is not None) and (subj_time[s]['t0'] is not None):\n",
    "        X_temp = (X['all'][subj_time[s]['t1']] - X['all'][subj_time[s]['t0']]).reshape(1, X['all'].shape[1])\n",
    "        X['delta1'].append(X_temp)\n",
    "        subjects['delta1'].append(s)\n",
    "        Y['delta1'].append(Y['all'][indeces_temp[0]])\n",
    "    print \"After 1 if for subject\", s\n",
    "    if (subj_time[s]['t2'] is not None) and (subj_time[s]['t1'] is not None):\n",
    "        X_temp = (X['all'][subj_time[s]['t2']] - X['all'][subj_time[s]['t1']]).reshape(1, X['all'].shape[1])\n",
    "        X['delta2'].append(X_temp)\n",
    "        subjects['delta2'].append(s)\n",
    "        Y['delta2'].append(Y['all'][indeces_temp[0]])\n",
    "    print \"After 2 if for subject\", s\n",
    "    if (subj_time[s]['t2'] is not None and subj_time[s]['t0'] is not None):\n",
    "        X_temp = (X['all'][subj_time[s]['t2']] - X['all'][subj_time[s]['t0']]).reshape(1, X['all'].shape[1])\n",
    "        X['delta3'].append(X_temp)\n",
    "        subjects['delta3'].append(s)\n",
    "        Y['delta3'].append(Y['all'][indeces_temp[0]])\n",
    "    print \"After 3 if for subject\", s\n",
    "    if subj_time[s]['t0'] is not None:\n",
    "        X_temp = (X['all'][subj_time[s]['t0']]).reshape(1, X['all'].shape[1])\n",
    "        X['t0'].append(X_temp) \n",
    "        subjects['t0'].append(s)\n",
    "        Y['t0'].append(Y['all'][indeces_temp[0]])\n",
    "    print \"After 4 if for subject\", s\n",
    "    if subj_time[s]['t1'] is not None:\n",
    "        X_temp = (X['all'][subj_time[s]['t1']]).reshape(1, X['all'].shape[1])\n",
    "        X['t1'].append(X_temp) \n",
    "        subjects['t1'].append(s)\n",
    "        Y['t1'].append(Y['all'][indeces_temp[0]])\n",
    "    print \"After 5 if for subject\", s\n",
    "    if subj_time[s]['t2'] is not None:\n",
    "        X_temp = (X['all'][subj_time[s]['t2']]).reshape(1, X['all'].shape[1])\n",
    "        X['t2'].append(X_temp) \n",
    "        subjects['t2'].append(s)\n",
    "        Y['t2'].append(Y['all'][indeces_temp[0]])\n",
    "    print \"After 6 if for subject\", s\n",
    "    \n",
    "X['delta1'] = np.vstack(X['delta1']).transpose()\n",
    "X['delta2'] = np.vstack(X['delta2']).transpose()\n",
    "X['delta3'] = np.vstack(X['delta3']).transpose()\n",
    "X['t0'] = np.vstack(X['t0']).transpose()\n",
    "X['t1'] = np.vstack(X['t1']).transpose()\n",
    "X['t2'] = np.vstack(X['t2']).transpose()\n",
    "\n",
    "numpy.savetxt(\"X_delta1.csv\", X['delta1'], delimiter=\",\")\n",
    "numpy.savetxt(\"X_delta2.csv\", X['delta2'], delimiter=\",\")\n",
    "numpy.savetxt(\"X_delta3.csv\", X['delta3'], delimiter=\",\")\n",
    "numpy.savetxt(\"Y_delta1.csv\", np.array(Y['delta1']), delimiter=\",\")\n",
    "numpy.savetxt(\"Y_delta2.csv\", np.array(Y['delta2']), delimiter=\",\")\n",
    "numpy.savetxt(\"Y_delta3.csv\", np.array(Y['delta3']), delimiter=\",\")\n",
    "numpy.savetxt(\"X_t1.csv\", X['t1'], delimiter=\",\")\n",
    "numpy.savetxt(\"X_t2.csv\", X['t2'], delimiter=\",\")\n",
    "numpy.savetxt(\"X_t0.csv\", X['t0'], delimiter=\",\")\n",
    "numpy.savetxt(\"Y_t1.csv\", np.array(Y['t1']), delimiter=\",\")\n",
    "numpy.savetxt(\"Y_t2.csv\", np.array(Y['t2']), delimiter=\",\")\n",
    "numpy.savetxt(\"Y_t0.csv\", np.array(Y['t0']), delimiter=\",\")\n",
    "numpy.savetxt(\"subj_t1.csv\", np.array(subjects['t1']), delimiter=\",\")\n",
    "numpy.savetxt(\"subj_t2.csv\", np.array(subjects['t2']), delimiter=\",\")\n",
    "numpy.savetxt(\"subj_t0.csv\", np.array(subjects['t0']), delimiter=\",\")\n",
    "numpy.savetxt(\"subj_delta1.csv\", np.array(subjects['delta1']), delimiter=\",\")\n",
    "numpy.savetxt(\"subj_delta2.csv\", np.array(subjects['delta2']), delimiter=\",\")\n",
    "numpy.savetxt(\"subj_delta3.csv\", np.array(subjects['delta3']), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
