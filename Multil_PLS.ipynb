{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "import random\n",
    "import pandas as pd\n",
    "from sys import exit\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# USUAL PLS\n",
    "\n",
    "def perform_pls(X, Y, n_comp, mean):\n",
    "    PLS_model = PLSRegression(n_comp, scale=True) #initialize a generic PLS model with parameters\n",
    "    \n",
    "    PLS_model.fit(X, Y) #ACTUALLY doing the PLS, fit model to data\n",
    "    \n",
    "    pred = PLS_model.predict(X) #predict the values on the train set\n",
    "    \n",
    "    Y_temp = np.array(Y)\n",
    "    pred_temp = pred.flatten()\n",
    "    \n",
    "    diff = Y_temp - pred_temp  \n",
    "    \n",
    "    #print \"Y_temp before: \", Y_temp\n",
    "    #print \"pred_temp before: \", pred_temp\n",
    "    \n",
    "    Y_temp = Y_temp+mean\n",
    "    pred_temp = pred_temp+mean\n",
    "    for j in range(len(pred_temp)):\n",
    "        if pred_temp[j]>1:\n",
    "            pred_temp[j]=1 \n",
    "        elif pred_temp[j]<0:\n",
    "            pred_temp[j]=0\n",
    "    pred_temp = np.rint(pred_temp)\n",
    "    for j in range(len(Y_temp)):\n",
    "        if Y_temp[j]>1:\n",
    "            Y_temp[j]=1 \n",
    "        elif Y_temp[j]<0:\n",
    "             Y_temp[j]=0\n",
    "    pred_temp = np.rint(pred_temp)\n",
    "    \n",
    "    #print \"Y_temp after: \", Y_temp\n",
    "    #print \"pred_temp after: \", pred_temp\n",
    "    \n",
    "    #print \"Training ROC curve:\"\n",
    "    fpr, tpr, auc = get_roc_auc(Y_temp, pred_temp)\n",
    "    #plot_roc_curve(fpr, tpr, auc)\n",
    "    \n",
    "    #diff = Y_temp - pred_temp             #see the difference\n",
    "    #print \"Difference: \",diff\n",
    "    #print \"Type of difference: \", type(diff)\n",
    "    train_error = sum(diff*diff) #calculate square error\n",
    "    #print \"Train AUC: \", auc\n",
    "    #print \"Training error: \", train_error\n",
    "    return PLS_model, train_error, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_data(matrix, mean=None):\n",
    "    if mean is None:\n",
    "        matrix = matrix - np.mean(matrix, axis=0)\n",
    "    else:\n",
    "        matrix = matrix - mean\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(matrix, deviation, ddof):\n",
    "    if deviation is None:\n",
    "        matrix = matrix/np.std(matrix, axis=0, ddof=ddof)\n",
    "    else:\n",
    "        matrix = matrix/deviation\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_auc(labels, predictions):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(labels, predictions) #compute precision-recall curve\n",
    "    if np.isnan(tpr).any():\n",
    "        tpr = np.ones(tpr.shape)\n",
    "    if np.isnan(fpr).any():\n",
    "        fpr = np.ones(fpr.shape)\n",
    "    auc = metrics.auc(fpr, tpr) #compute area under the curve for this run\n",
    "    return fpr, tpr, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, auc):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULTILEVEL PLS\n",
    "def perform_multilevel_pls(X, Y, subj, unique_subj, num_unique_subj, num_subj, scaling, par, n_comp, ddof):\n",
    "    #mean-centering\n",
    "    X_centered = center_data(X) #mean centering of data\n",
    "    Y_centered = center_data(Y) #FIXME :think about Y and scaling/centering\n",
    "\n",
    "    #split matrix into between and within subject variations\n",
    "    Xb, Xw = split_between_within_subject_matrix(X_centered, subj, unique_subj, num_unique_subj, num_subj)\n",
    "    \n",
    "    #scaling (if necessary and specified)\n",
    "    if scaling: #scale the data, if the flag is true\n",
    "        X_scaled = scale_data(X_centered,None, ddof)\n",
    "        Y_scaled = scale_data(Y_centered, None, ddof)                          \n",
    "        #Y_scaled = Y_centered\n",
    "        Xb_scaled = scale_data(Xb,None, ddof)\n",
    "        Xw_scaled = scale_data(Xw,None, ddof)\n",
    "    else:\n",
    "        X_scaled = X_centered\n",
    "        Y_scaled = Y_centered\n",
    "        Xb_scaled = Xb\n",
    "        Xw_scaled = Xw\n",
    "    \n",
    "    #which matrix are we interested in\n",
    "    #print \"Using (in the usual PLS) the matrix \", par\n",
    "    if par==\"all\":\n",
    "        model, train_error, train_auc = perform_pls(X_scaled, Y_scaled, n_comp=n_comp, mean=np.mean(Y)) #perform usual pls on whole dataset\n",
    "    elif par==\"between\":\n",
    "        model, train_error, train_auc = perform_pls(X=Xb_scaled, Y=Y_scaled, n_comp=n_comp, mean=np.mean(Y)) #perform usual PLS on between subject variation\n",
    "    elif par==\"within\":\n",
    "        model, train_error, train_auc = perform_pls(Xw_scaled, Y_scaled, n_comp=7, mean=np.mean(Y)) #perform usual PLS on within subject variation\n",
    "    \n",
    "    return model, train_error, train_auc, Xb_scaled, Xw_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_train_test(X, Y, subj, unique_subj, num_subj, num_unique_subj, num_subj_in_fold):\n",
    "    \n",
    "    X_train = None #initialization\n",
    "    X_test = None\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "    subj_train = []\n",
    "    subj_test = []\n",
    "    \n",
    "    test_subj = np.random.choice(unique_subj, num_subj_in_fold, replace=False) #choose subjects for test set\n",
    "    train_subj = np.setdiff1d(unique_subj, test_subj)                           #other subjects => train set\n",
    "\n",
    "    #create the test and train dataset from matrix X with chosen subjects\n",
    "    while(True):\n",
    "        for j in range(num_subj):\n",
    "            if subj[j] in train_subj: \n",
    "                if X_train is not None:\n",
    "                    X_train = np.vstack([X_train, X[j]]) \n",
    "                else : \n",
    "                    X_train = np.matrix(X[j])\n",
    "                Y_train.append(Y[j]) \n",
    "                subj_train.append(subj[j])\n",
    "            else:\n",
    "                if X_test is not None:\n",
    "                    X_test = np.vstack([X_test, X[j]])\n",
    "                else : \n",
    "                    X_test = np.matrix(X[j]) \n",
    "                Y_test.append(Y[j]) \n",
    "                subj_test.append(subj[j])\n",
    "        n_unique_test = len(np.unique(Y_train))\n",
    "        if n_unique_test>1:\n",
    "            break\n",
    "        \n",
    "        #X_train = X_train.astype(int)                   #FIXME scaling\n",
    "        #X_test = X_test.astype(int)\n",
    "                \n",
    "    num_train_subj = len(subj_train)          #how many entries in train dataset\n",
    "    num_test_subj= num_subj - num_train_subj  #how many entries in test dataset\n",
    "    num_unique_train_subj = num_unique_subj - num_subj_in_fold\n",
    "    num_unique_test_subj = num_subj_in_fold\n",
    "        \n",
    "    return X_train, X_test, Y_train, Y_test, subj_train, subj_test, num_train_subj, num_test_subj, num_unique_train_subj, num_unique_test_subj, train_subj, test_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_train_test_old(X, Y, subj, unique_subj, num_subj, num_unique_subj, num_subj_in_fold):\n",
    "    \n",
    "    X_train = None #initialization\n",
    "    X_test = None\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "    subj_train = []\n",
    "    subj_test = []\n",
    "    \n",
    "    test_subj = np.random.choice(unique_subj, num_subj_in_fold, replace=False) #choose subjects for test set\n",
    "    train_subj = np.setdiff1d(unique_subj, test_subj)                           #other subjects => train set\n",
    "\n",
    "    #create the test and train dataset from matrix X with chosen subjects\n",
    "    for j in range(num_subj):\n",
    "        if subj[j] in train_subj: \n",
    "            if X_train is not None:\n",
    "                X_train = np.vstack([X_train, X[j]]) \n",
    "            else : \n",
    "                X_train = np.matrix(X[j])\n",
    "            Y_train.append(Y[j]) \n",
    "            subj_train.append(subj[j])\n",
    "        else:\n",
    "            if X_test is not None:\n",
    "                X_test = np.vstack([X_test, X[j]])\n",
    "            else : \n",
    "                X_test = np.matrix(X[j]) \n",
    "            Y_test.append(Y[j]) \n",
    "            subj_test.append(subj[j])\n",
    "\n",
    "        #X_train = X_train.astype(int)                   #FIXME scaling\n",
    "        #X_test = X_test.astype(int)\n",
    "                \n",
    "    num_train_subj = len(subj_train)          #how many entries in train dataset\n",
    "    num_test_subj= num_subj - num_train_subj  #how many entries in test dataset\n",
    "    num_unique_train_subj = num_unique_subj - num_subj_in_fold\n",
    "    num_unique_test_subj = num_subj_in_fold\n",
    "        \n",
    "    return X_train, X_test, Y_train, Y_test, subj_train, subj_test, num_train_subj, num_test_subj, num_unique_train_subj, num_unique_test_subj, train_subj, test_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CROSS-VALIDATION\n",
    "def cross_validation(X, Y, subj, unique_subj, num_subj, num_unique_subj, num_folds, num_repeats, scaling, par, n_comp, ddof):\n",
    "    \n",
    "    error = 0 #initialization\n",
    "    auc = 0\n",
    "    \n",
    "    #calculate number of subjects per 1 fold in cross-validation\n",
    "    if num_unique_subj>num_folds: \n",
    "        num_subj_in_fold = num_unique_subj/num_folds\n",
    "    else:\n",
    "        num_subj_in_fold = num_unique_subj\n",
    "\n",
    "    for i in range(num_repeats): #repeat cross_validation as many times as specified\n",
    "        X_train, X_test, Y_train, Y_test, subj_train, subj_test, num_train_subj, num_test_subj, num_unique_train_subj, num_unique_test_subj, train_subj, test_subj = separate_train_test_old(X, Y, subj, unique_subj, num_subj, num_unique_subj, num_subj_in_fold)\n",
    "        \n",
    "        #perform multilevel pls on TRAIN dataset\n",
    "        model, train_error, train_auc, Xb_train, Xw_train = perform_multilevel_pls(X=X_train, Y=Y_train, subj=subj_train, unique_subj=train_subj, num_unique_subj=num_unique_train_subj, num_subj=num_train_subj, scaling=scaling, par=par, n_comp=n_comp, ddof=ddof)\n",
    "        \n",
    "        #Xb_train = Xb_train.astype(int)\n",
    "        #Xw_train = Xw_train.astype(int) #FIXME scaling\n",
    "        \n",
    "        X_train_mean = np.mean(X_train)\n",
    "        Y_train_mean = np.mean(Y_train)\n",
    "        \n",
    "        X_centered_test = center_data(X_test, X_train_mean) #mean centering of data\n",
    "        Y_centered_test = center_data(Y_test, Y_train_mean)                        #FIXME : centering and scaling\n",
    "        #Y_centered_test = Y_test - np.mean(Y_train, axis=0)\n",
    "        #X_centered_test =  X_centered_test.astype(int) #for std\n",
    "        #Y_centered_test =  Y_centered_test.astype(int)\n",
    "        \n",
    "\n",
    "        #split test data into between and within subject variation\n",
    "        Xb_test, Xw_test = split_between_within_subject_matrix(X=X_centered_test, subj=subj_test, unique_subj=test_subj,num_unique_subj=num_unique_test_subj, num_subj=num_test_subj )\n",
    "        #Xb_test = Xb_test.astype(int)\n",
    "        #Xw_test = Xw_test.astype(int) #FIXME scaling     \n",
    "\n",
    "        if scaling: #scale the data, if the flag is true\n",
    "            X_train_deviation = np.std(X_train, axis = 0, ddof=ddof)\n",
    "            Y_train_deviation = np.std(Y_train, axis = 0, ddof=ddof)\n",
    "            Xb_train_deviation = np.std(Xb_train, axis = 0, ddof=ddof)\n",
    "            Xw_train_deviation = np.std(Xw_train, axis = 0, ddof=ddof)\n",
    "            \n",
    "            X_scaled_test = scale_data(X_centered_test, X_train_deviation, ddof)\n",
    "            Y_scaled_test = scale_data(Y_centered_test, Y_train_deviation, ddof)\n",
    "            \n",
    "            Xb_scaled_test = scale_data(Xb_test, Xb_train_deviation, ddof)\n",
    "            Xw_scaled_test = scale_data(Xw_test, Xw_train_deviation, ddof)\n",
    "        else:\n",
    "            \n",
    "            X_scaled_test = X_centered_test\n",
    "            Y_scaled_test = Y_centered_test\n",
    "            Xb_scaled_test = Xb_test\n",
    "            Xw_scaled_test = Xw_test\n",
    "            \n",
    "        #print \"Use the model to predict the test values for matrix \", par   \n",
    "        pred = model.predict(X_scaled_test) #predict test data with model trained on the training set\n",
    "        #if only between or only within subject variations chosen, predict on that part of the matrix\n",
    "        if par==\"between\":\n",
    "             pred = model.predict(Xb_scaled_test)\n",
    "        elif par==\"within\":\n",
    "             pred = model.predict(Xw_scaled_test)   \n",
    "            \n",
    "        diff = Y_scaled_test - pred         #see the differences\n",
    "        error = error + sum(sum(diff*diff)) #compute square error\n",
    "        \n",
    "        #bring labels and predictions to binary (0 or 1)\n",
    "        Y_test = np.array(Y_test)\n",
    "        pred = pred.flatten()+Y_train_mean\n",
    "        for j in range(len(pred)):\n",
    "            if pred[j]>1:\n",
    "                pred[j]=1 \n",
    "            elif pred[j]<0:\n",
    "                pred[j]=0\n",
    "        pred = np.rint(pred)\n",
    "        \n",
    "        #compute ROC curve and AUC\n",
    "        fpr, tpr, auc_temp = get_roc_auc(Y_test, pred)\n",
    "        auc = auc+auc_temp #sum of all AUC scores (to then get a mean AUC score)\n",
    "        \n",
    "        #plot ROC curve, if want\n",
    "        #if i%10==0:\n",
    "        #    plot_roc_curve(fpr, tpr, auc_temp)\n",
    "        \n",
    "    error = error/num_repeats #mean error for cross-validation\n",
    "    auc = auc/num_repeats     #mean AUC score for cross validation\n",
    "    \n",
    "    print \"Y: \", Y\n",
    "    print \"Y transposed: \", Y.transpose()\n",
    "    print \"Result of the multiplicaton: \", np.matmul(Y, Y.transpose())\n",
    "    print \"Number of subjects: \", num_subj\n",
    "    print \"Error: \", error\n",
    "    print \"To subtract:\", error/(np.matmul(Y, Y.transpose())/num_subj)\n",
    "    Q = 1 - error/(np.matmul(Y, Y.transpose())/num_subj)\n",
    "    print \"Mean cross-validation error: \", error\n",
    "    print \"Mean AUC: \", auc\n",
    "    print \"Q: \", Q\n",
    "    return error, auc, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL SCRIPT\n",
    "def full_script(num_folds, num_repeats, scaling, num_permutations, par, filename, n_comp, ddof):\n",
    "    #READ OR MAKE UP DATA\n",
    "    X, Y, subj = read_data(filename)\n",
    "\n",
    "    unique_subj = np.unique(subj) #create list of unique subjects\n",
    "    num_subj = len(subj)        #the number of entries = number of subjects corresponding to entries (1 subject per entry)\n",
    "    num_unique_subj = len(unique_subj) #the number of unique subjects\n",
    "    error = 0 #initialization\n",
    "\n",
    "    #PERFORMING MULTILEVEL PLS ON WHOLE DATASET\n",
    "    full_model, full_train_error, full_train_auc, Xb, Xw = perform_multilevel_pls(X=X, Y=Y, subj=subj, unique_subj=unique_subj, num_subj=num_subj, num_unique_subj=num_unique_subj, scaling=scaling, par=par, n_comp=n_comp, ddof=ddof)\n",
    "    \n",
    "    #CROSS-VALIDATION\n",
    "    crossval_error, crossval_auc, crossval_Q = cross_validation(X, Y, subj, unique_subj, num_subj, num_unique_subj, num_folds, num_repeats, scaling, par, n_comp=n_comp, ddof=ddof)\n",
    "    \n",
    "    #PERMUTATE\n",
    "    print \"Permutation errors: \"\n",
    "    permutation_error, permutation_auc, permutation_Q= validate_permutation(X=X, Y=Y, subj=subj, unique_subj=unique_subj, num_subj=num_subj, num_unique_subj=num_unique_subj, num_folds=num_folds, num_repeats=num_repeats, scaling=scaling, num_permutations=num_permutations, par=par, n_comp=n_comp, ddof=ddof)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data matrix nito between and within subject variations\n",
    "def split_between_within_subject_matrix(X, subj, unique_subj, num_unique_subj, num_subj): #SPLIT MATRIX \n",
    "    Xb = np.zeros(X.shape) #initialization\n",
    "    Xw = np.zeros(X.shape)\n",
    "    means = np.zeros((num_unique_subj, X.shape[1]))\n",
    "    for j in range(num_unique_subj): #go through all unique subjects\n",
    "        idx = np.where(np.array(subj)==unique_subj[j]) #find indexes of all entries for a certain subject (unique_subj[j])\n",
    "        means[j] = np.mean(X[idx[0]], axis=0)   #calculate mean for each subject unique_subj[j]        \n",
    "    for i in range(num_subj): #go through subjects of all entries\n",
    "        k = np.where(unique_subj==subj[i]) #find the index of the subject corresponding to subj[i] in unique_subj\n",
    "        Xb[i] = means[k[0][0]]                  #create a matrix where all entries for subject = mean (between subject variation)\n",
    "    \n",
    "    Xw = X - Xb             #FIXME make sure of within subject variation\n",
    "    return Xb, Xw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERMUTATION\n",
    "def validate_permutation(X, Y, subj, unique_subj, num_subj, num_unique_subj, num_folds, num_repeats, scaling, num_permutations, par, n_comp, ddof):\n",
    "    err = [] #initialization\n",
    "    auc = []\n",
    "    Q = []\n",
    "    for i in range(num_permutations):#perform permutations as many times as specified\n",
    "        Y_temp = Y  #create temporary labels which then shuffle/permutate, so original is left untouched\n",
    "        \n",
    "        np.random.shuffle(Y_temp) #randomly shuffle the Y(labels) vector. Checks if your results will be similar\n",
    "        \n",
    "        #perform cross-validation for each permutation and get an array of accuracies when permutated\n",
    "        err_temp, auc_temp, Q_temp = cross_validation(X, Y_temp, subj, unique_subj, num_subj, num_unique_subj, num_folds, num_repeats, scaling, par, n_comp, ddof)\n",
    "        err.append(err_temp)\n",
    "        auc.append(auc_temp)\n",
    "        Q.append(Q_temp)\n",
    "    if len(err) >0 :\n",
    "        print \"Mean permutated squared error : \", np.mean(err)\n",
    "        print \"Mean permutated auc : \", np.mean(auc)\n",
    "        print \"Mean permutated Q: \", np.mean(Q)\n",
    "    else:\n",
    "        print \"No permutations performed\"\n",
    "    return err, auc, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name=None):\n",
    "    if file_name is None: #if no input file specified, make up data\n",
    "        print \"WARNING : results are nonsence, working on MADE UP data. Only for debugging, testing purposes.\"\n",
    "        X =  np.random.rand(140, 300) \n",
    "        Y =  np.random.rand(140, 1)\n",
    "        subjects = [random.randint(1, 35) for i in range(140)]\n",
    " \n",
    "    else:\n",
    "        data = pd.read_excel(file_name) #read the excel file\n",
    "        subjects = data.head().ix[-2].values[0:148].astype(int) #take relevant values as subkect id's, convert to int\n",
    "        Y = (data.head().ix[-3].values[0:148]=='risk').astype(int)#take relevant values as labels, convert to int\n",
    "        X = data.as_matrix()[7:, :-9].transpose().astype(int)   #take the matabolite matrix, transpose, convert to int\n",
    "    return X, Y, subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anna/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/anna/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/anna/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:  [0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1\n",
      " 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1\n",
      " 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "Y transposed:  [0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1\n",
      " 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1\n",
      " 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "Result of the multiplicaton:  63\n",
      "Number of subjects:  148\n",
      "Error:  3.402936940239801e+17\n",
      "To subtract: inf\n",
      "Mean cross-validation error:  3.402936940239801e+17\n",
      "Mean AUC:  0.5106198509504134\n",
      "Q:  -inf\n",
      "Permutation errors: \n",
      "No permutations performed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anna/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:92: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/home/anna/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:93: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_script(num_folds=5, num_repeats=200, scaling=True, num_permutations=0, par='between', filename='OGTT_INPUT.xlsx', n_comp=8, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
